# -*- coding: utf-8 -*-
# ===========================================================
# å»ºç‰©è¨ºæ–­ãã‚“ï¼ˆã‚¹ãƒãƒ›å¯¾å¿œãƒ»å…ˆé€²UIï¼‰
# æ©Ÿèƒ½ã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã‚’ç¶­æŒã—ã¤ã¤ã€UI/UXã‚’å¤§å¹…ã«æ”¹å–„ã€‚
# RAGï¼ˆBM25+ãƒ–ãƒ¼ã‚¹ãƒˆï¼‰ï¼‹ ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼ˆä¸€èˆ¬åŸå‰‡ï¼‰ï¼‹ ç”»åƒã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ‰€è¦‹ â†’ Gemini 2.5 Flash
# - å¯è¦–/èµ¤å¤–ï¼šã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ or ã‚«ãƒ¡ãƒ©ï¼ˆ1æšãšã¤ï¼‰
# - ç«¯æœ«ã®ç¾åœ¨åœ°ï¼ˆGeolocationï¼‰ï¼‹ Folium åœ°å›³
# - â€œçµæœã®ã¿â€ï¼šç·åˆè©•ä¾¡ã‚’æœ€åˆã«ã€è©³ç´°ã¯ Expander
# - CSSã¯ components.html ã§éè¡¨ç¤ºæŒ¿å…¥
# Python 3.12 äº’æ›ãƒ»è»½é‡ä¾å­˜
# ===========================================================

# Python 3.12: pkgutil.ImpImporterå‰Šé™¤å›é¿ï¼ˆå¤ã„ä¾å­˜å¯¾ç­–ï¼‰
import pkgutil
if not hasattr(pkgutil, "ImpImporter"):
    pkgutil.ImpImporter = pkgutil.zipimporter

import os
import io
import re
import math
import base64
import statistics
import unicodedata
from typing import List, Tuple, Dict, Optional, Any

import streamlit as st
import requests
import PyPDF2
from PIL import Image, ImageFilter

# åœ°å›³
import folium
from streamlit_folium import st_folium
from streamlit import components

# geolocationï¼ˆä»»æ„ï¼‰
HAVE_GEO = False
try:
    from streamlit_geolocation import st_geolocation
    HAVE_GEO = True
except Exception:
    HAVE_GEO = False

APP_TITLE = "å»ºç‰©è¨ºæ–­ãã‚“"

PDF_SOURCES = [
    ("Structure_Base.pdf", "Structure_Base.pdf"),
    ("ä¸Šå³¶ç”º å…¬å…±æ–½è¨­ç­‰ç·åˆç®¡ç†è¨ˆç”»", "kamijimachou_Public_facility_management_plan.pdf"),
    ("æ¸¯åŒº å…¬å…±æ–½è¨­ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆè¨ˆç”»", "minatoku_Public_facility_management_plan.pdf"),
]

MAX_SNIPPETS = 6
MAX_SNIPPET_CHARS = 900

QUERY_SYNONYMS = {
    "ã²ã³å‰²ã‚Œ": ["ã²ã³å‰²ã‚Œ", "ã‚¯ãƒ©ãƒƒã‚¯", "äº€è£‚", "ã²ã³"],
    "æµ®ã": ["æµ®ã", "ã†ã"],
    "å‰¥é›¢": ["å‰¥é›¢", "ã¯ãé›¢", "ã¯ãã‚Š"],
    "å«æ°´": ["å«æ°´", "æµ¸æ°´", "æ¼æ°´", "é›¨æ°´ä¾µå…¥"],
    "èµ¤å¤–ç·š": ["èµ¤å¤–ç·š", "IR", "ã‚µãƒ¼ãƒ¢", "ç†±ç”»åƒ", "ã‚µãƒ¼ãƒ¢ã‚°ãƒ©ãƒ•ã‚£"],
    "åŸºæº–": ["åŸºæº–", "åˆ¤å®š", "è©•ä¾¡", "é–¾å€¤"],
    "ã‚¿ã‚¤ãƒ«": ["ã‚¿ã‚¤ãƒ«", "ç£å™¨è³ªã‚¿ã‚¤ãƒ«", "ãƒ¢ã‚¶ã‚¤ã‚¯ã‚¿ã‚¤ãƒ«"],
    "ALC": ["ALC", "è»½é‡æ°—æ³¡ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ"],
    "ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ": ["ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ", "RC", "ä¸­æ€§åŒ–"],
    "é˜²æ°´": ["é˜²æ°´", "å¡—è†œ", "ã‚·ãƒ¼ãƒªãƒ³ã‚°", "ä¼¸ç¸®ç›®åœ°"],
    "åŠ£åŒ–åº¦": ["åŠ£åŒ–åº¦", "ã‚°ãƒ¬ãƒ¼ãƒ‰", "åŒºåˆ†", "A", "B", "C", "D"],
}

# -------------------------- ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç† --------------------------
def normalize_text(text: str) -> str:
    text = unicodedata.normalize("NFKC", text)
    text = text.replace("\r", " ").replace("\n", " ")
    text = re.sub(r"\s+", " ", text).strip()
    return text

def tokenize(s: str) -> List[str]:
    s = s.lower()
    s = re.sub(r"[^\wä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³ï¼…â„ƒï¼\.]", " ", s)
    s = s.replace("ï¼", ".")
    s = re.sub(r"\s+", " ", s).strip()
    return s.split()

def query_expand_tokens(q: str) -> List[str]:
    tokens = set(tokenize(q))
    for key, syns in QUERY_SYNONYMS.items():
        if key in q or any(s in q for s in syns):
            for s in syns:
                tokens.update(tokenize(s))
    return list(tokens)

# -------------------------- PDF â†’ ãƒãƒ£ãƒ³ã‚¯ --------------------------
def extract_chunks_from_pdf(pdf_path: str, title: str,
                            max_chars: int = 900, overlap: int = 120) -> List[Dict[str, Any]]:
    if not os.path.exists(pdf_path):
        return []
    chunks: List[Dict[str, Any]] = []
    try:
        with open(pdf_path, "rb") as f:
            reader = PyPDF2.PdfReader(f)
            for i, page in enumerate(reader.pages, start=1):
                t = page.extract_text() or ""
                page_text = normalize_text(t)
                if not page_text:
                    continue
                pos = 0
                while pos < len(page_text):
                    end = min(pos + max_chars, len(page_text))
                    ch = page_text[pos:end].strip()
                    if ch:
                        chunks.append({
                            "doc": title,
                            "path": pdf_path,
                            "text": ch,
                            "page_start": i,
                            "page_end": i,
                        })
                    pos = end - overlap if (end - overlap) > pos else end
    except Exception as e:
        chunks.append({
            "doc": title, "path": pdf_path,
            "text": f"[PDFèª­è¾¼ã‚¨ãƒ©ãƒ¼:{pdf_path}:{e}]",
            "page_start": None, "page_end": None
        })
    return chunks

# -------------------------- BM25 ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ --------------------------
class BM25Index:
    def __init__(self, k1: float = 1.6, b: float = 0.75):
        self.k1, self.b = k1, b
        self.N = 0
        self.avgdl = 0.0
        self.df: Dict[str, int] = {}
        self.doc_len: List[int] = []
        self.postings: Dict[str, List[Tuple[int, int]]] = {}
        self.docs: List[Dict[str, Any]] = []

    @staticmethod
    def _tf(tokens: List[str]) -> Dict[str, int]:
        tf: Dict[str, int] = {}
        for t in tokens:
            tf[t] = tf.get(t, 0) + 1
        return tf

    def build(self, docs: List[Dict[str, Any]]):
        self.docs = docs
        self.N = len(docs)
        lengths = []
        for doc_id, d in enumerate(docs):
            tokens = tokenize(d["text"])
            d["_tokens"] = tokens
            tf = self._tf(tokens)
            lengths.append(len(tokens))
            for term, c in tf.items():
                self.df[term] = self.df.get(term, 0) + 1
                self.postings.setdefault(term, []).append((doc_id, c))
        self.doc_len = lengths
        self.avgdl = (sum(lengths) / self.N) if self.N else 0.0

    def idf(self, term: str) -> float:
        df = self.df.get(term, 0)
        return math.log((self.N - df + 0.5) / (df + 0.5) + 1.0)

    def score_doc(self, q_tokens: List[str], doc_id: int) -> float:
        score = 0.0
        dl = self.doc_len[doc_id] if doc_id < len(self.doc_len) else 0
        if dl == 0:
            return 0.0
        for term in set(q_tokens):
            plist = self.postings.get(term)
            if not plist:
                continue
            tf = 0
            for did, c in plist:
                if did == doc_id:
                    tf = c
                    break
            if tf == 0:
                continue
            idf = self.idf(term)
            denom = tf + self.k1 * (1 - self.b + self.b * (dl / (self.avgdl or 1.0)))
            score += idf * (tf * (self.k1 + 1)) / (denom or 1.0)
        return score

@st.cache_resource(show_spinner=False)
def build_rag() -> Dict[str, Any]:
    all_chunks: List[Dict[str, Any]] = []
    for title, path in PDF_SOURCES:
        all_chunks.extend(extract_chunks_from_pdf(path, title))
    # è¿½åŠ ãƒ¡ã‚¿
    for d in all_chunks:
        txt = d["text"]
        d["_has_numbers"] = bool(re.search(r"\b\d+(\.\d+)?\s*(mm|ãœ|ï¼…|%|â„ƒ)\b", txt))
        d["_has_ir"] = any(k in txt for k in ["èµ¤å¤–ç·š", "ã‚µãƒ¼ãƒ¢", "IR", "ç†±ç”»åƒ", "æ”¾å°„ç‡", "åå°„æ¸©åº¦"])
    bm25 = BM25Index()
    if all_chunks:
        bm25.build(all_chunks)
    return {"index": bm25, "docs": all_chunks}

def rag_search(query: str, have_ir: bool, k: int = MAX_SNIPPETS) -> List[Dict[str, Any]]:
    data = build_rag()
    bm25: BM25Index = data["index"]
    docs = data["docs"]
    if not docs:
        return []
    q_tokens = query_expand_tokens(query)
    want_threshold = any(w in query for w in ["åŸºæº–", "é–¾å€¤", "å¹…", "mm", "ï¼…", "%", "â„ƒ", "æ¸©åº¦"])
    boost_muni = "æ¸¯åŒº" if "æ¸¯åŒº" in query else ("ä¸Šå³¶ç”º" if ("ä¸Šå³¶ç”º" in query or "ä¸Šå¶‹ç”º" in query) else None)

    scored: List[Tuple[float, int]] = []
    for doc_id, d in enumerate(docs):
        base = bm25.score_doc(q_tokens, doc_id)
        if want_threshold and d.get("_has_numbers"):
            base *= 1.12
        if have_ir and d.get("_has_ir"):
            base *= 1.10
        if boost_muni and boost_muni in d["doc"]:
            base *= 1.15
        if base > 0:
            scored.append((base, doc_id))
    scored.sort(key=lambda x: x[0], reverse=True)
    top = [docs[i] for (_, i) in scored[:k]]
    for t in top:
        if len(t["text"]) > MAX_SNIPPET_CHARS:
            t["text"] = t["text"][:MAX_SNIPPET_CHARS] + "â€¦"
    return top

# ---------------------- ç”»åƒã®è»½é‡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° ----------------------
def pil_stats(image: Image.Image) -> Dict[str, float]:
    """PILã ã‘ã§è»½é‡ã«ç”»ç´ çµ±è¨ˆã‚’å–ã‚‹ï¼ˆãƒªã‚µã‚¤ã‚ºã—ã¦è² è·è»½æ¸›ï¼‰"""
    if image.mode != "RGB":
        image = image.convert("RGB")
    w = 256 if image.width > 256 else image.width
    ratio = w / image.width
    image = image.resize((w, int(image.height * ratio)))
    gray = image.convert("L")
    pixels = list(gray.getdata())
    mean_l = statistics.fmean(pixels) if pixels else 0.0
    stdev_l = statistics.pstdev(pixels) if pixels else 0.0
    edges = gray.filter(ImageFilter.FIND_EDGES)
    epx = list(edges.getdata())
    strong = sum(1 for v in epx if v > 60)
    edge_ratio = strong / len(epx) if epx else 0.0
    hsv = image.convert("HSV")
    sat_vals = [p[1] for p in list(hsv.getdata())]
    sat_mean = statistics.fmean(sat_vals) if sat_vals else 0.0
    return {
        "mean_l": round(mean_l, 2),
        "stdev_l": round(stdev_l, 2),
        "edge_ratio": round(edge_ratio, 4),
        "sat_mean": round(sat_mean, 2),
    }

def analyze_visual(image: Image.Image) -> Dict[str, Any]:
    """å¯è¦–ç”»åƒã®ç°¡æ˜“æ‰€è¦‹ï¼ˆã²ã³å‚¾å‘/æ±šã‚Œå‚¾å‘ãªã©ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰"""
    s = pil_stats(image)
    crack_hint = s["edge_ratio"] > 0.11
    stain_hint = s["sat_mean"] < 70 and s["mean_l"] < 110
    level = "low"
    if crack_hint and stain_hint: level = "mid"
    if s["edge_ratio"] > 0.16: level = "mid"
    if s["edge_ratio"] > 0.22: level = "high"
    return {
        "metrics": s,
        "crack_hint": crack_hint,
        "stain_hint": stain_hint,
        "screening_level": level,
        "note": "ç”»åƒãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“å‚¾å‘ã€‚å¯¸æ³•ãƒ»å¹…ãªã©ã¯ç”»åƒã ã‘ã§ã¯ç¢ºå®šã§ãã¾ã›ã‚“ã€‚"
    }

def analyze_ir(image: Image.Image, meta: Dict[str, str]) -> Dict[str, Any]:
    """IRç”»åƒã®ç›¸å¯¾æ¸©åº¦å·®ï¼ˆè¼åº¦å·®ï¼‰ã‚’ç°¡æ˜“è©•ä¾¡"""
    gray = image.convert("L")
    w = 256 if gray.width > 256 else gray.width
    gray = gray.resize((w, int(gray.height * (w / gray.width))))
    vals = list(gray.getdata())
    if not vals:
        return {"has_ir": True, "delta_rel": 0.0, "pattern": "unknown", "note": "ç”»åƒãƒ‡ãƒ¼ã‚¿ç„¡ã—"}
    vmin, vmax = min(vals), max(vals)
    delta = vmax - vmin
    stdev = statistics.pstdev(vals)
    pattern = "uniform"
    if stdev > 20 and delta > 40: pattern = "hot/cold spots"
    if stdev > 30 and delta > 60: pattern = "strong hotspots"
    return {
        "has_ir": True,
        "delta_rel": round(delta / 255.0, 3),
        "stdev": round(stdev, 2),
        "pattern": pattern,
        "meta": meta,
        "note": "JPEGã®è¼åº¦å·®ã‹ã‚‰è¦‹ãŸç›¸å¯¾çš„ãªãƒ ãƒ©è©•ä¾¡ã€‚æ”¾å°„ç‡/åå°„æ¸©åº¦ç­‰ã®è£œæ­£ç„¡ã—ã€‚"
    }

# ---------------------- ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆæˆï¼ˆå®‰å…¨å´ï¼‰ ----------------------
def rule_based_grade(vis: Optional[Dict[str, Any]], ir: Optional[Dict[str, Any]]) -> Tuple[str, str]:
    """ç”»åƒã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ‰€è¦‹ã‹ã‚‰ Aâ€“D ã®æš«å®šã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’æ¨å®šï¼ˆå®‰å…¨å´ï¼‰"""
    score = 0.0
    reasons = []
    if vis:
        er = vis["metrics"]["edge_ratio"]
        if er > 0.22: score += 3; reasons.append(f"å¼·ã„ã‚¨ãƒƒã‚¸å¯†åº¦(edge_ratio={er})")
        elif er > 0.16: score += 2; reasons.append(f"é«˜ã‚ã®ã‚¨ãƒƒã‚¸å¯†åº¦(edge_ratio={er})")
        elif er > 0.11: score += 1; reasons.append(f"ã‚„ã‚„é«˜ã„ã‚¨ãƒƒã‚¸å¯†åº¦(edge_ratio={er})")
        if vis.get("stain_hint"): score += 1; reasons.append("ä½å½©åº¦ãƒ»æš—éƒ¨å¤šã‚ã§æ±šæŸ“å‚¾å‘")
    if ir and ir.get("has_ir"):
        dr = ir["delta_rel"]
        if dr > 0.5: score += 3; reasons.append(f"IRè¼åº¦å·®ãŒå¤§(Î”ç›¸å¯¾={dr})")
        elif dr > 0.3: score += 2; reasons.append(f"IRè¼åº¦å·®ãŒä¸­(Î”ç›¸å¯¾={dr})")
        elif dr > 0.15: score += 1; reasons.append(f"IRè¼åº¦å·®ãŒã‚„ã‚„å¤§(Î”ç›¸å¯¾={dr})")
        if ir.get("pattern") in ("strong hotspots",): score += 1; reasons.append("å¼·ã„ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³")
    
    if score <= 1: g = "A"
    elif score <= 3: g = "B"
    elif score <= 5: g = "C"
    else: g = "D"
    return g, "ãƒ»".join(reasons) if reasons else "é¡•è‘—ãªç•°å¸¸ã¯æ¤œå‡ºã•ã‚Œãšï¼ˆç”»åƒãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“åˆ¤å®šï¼‰"

def rule_based_life(grade: str) -> str:
    """å‚è€ƒã®å¯¿å‘½å¹…"""
    mapping = {"A": "10â€“20å¹´(å‚è€ƒ)", "B": "7â€“15å¹´(å‚è€ƒ)", "C": "3â€“10å¹´(å‚è€ƒ)", "D": "1â€“5å¹´(å‚è€ƒ)"}
    return mapping.get(grade, "æœªè©•ä¾¡")

# ---------------------- ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼ˆä¸€èˆ¬åŸå‰‡ï¼‰ ----------------------
def domain_priors_text() -> str:
    return normalize_text("""
- å†™çœŸã®ã¿ã‹ã‚‰å¯¸æ³•ï¼ˆã²ã³å¹…ç­‰ï¼‰ã‚„ææ–™ç‰¹æ€§ã‚’æ­£ç¢ºã«æ±ºå®šã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€‚æ•°å€¤ãŒå¿…è¦ãªå ´åˆã¯æ ¹æ‹ æ–‡çŒ®ã®é–¾å€¤ã‚’å¼•ç”¨ã™ã‚‹ã€‚
- å¯è¦–ï¼šã‚¯ãƒ©ãƒƒã‚¯/ç›®åœ°åŠ£åŒ–ã¯é›¨æ°´æµ¸å…¥ãƒ»ä»•ä¸Šã’å‰¥é›¢ãƒ»èº¯ä½“åŠ£åŒ–ã«ã¤ãªãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
- èµ¤å¤–ç·šï¼šæ”¾å°„ç‡ãƒ»åå°„æ¸©åº¦ãƒ»å¤–æ°—æ¸©ãƒ»æ¹¿åº¦ãƒ»æ’®å½±è·é›¢/è§’åº¦ãƒ»é¢¨/æ—¥å°„ç­‰ã®æ¡ä»¶ã«å¼·ãå½±éŸ¿ã•ã‚Œã‚‹ã€‚JPEGã®ç–‘ä¼¼æ¸©åº¦ã¯çµ¶å¯¾å€¤ã¨ã—ã¦æ‰±ã‚ãªã„ã€‚
- å®‰å…¨ç¢ºä¿ï¼šå‰¥é›¢ãƒ»è½ä¸‹ãƒªã‚¹ã‚¯ãŒã‚ã‚‹å ´åˆã¯è¿‘æ¥èª¿æŸ»ï¼ˆæ‰“è¨º/ã¯ã¤ã‚Š/ä»˜ç€åŠ›ç­‰ï¼‰ã¨æ—©æœŸä»®è¨­é˜²è­·ã‚’æ¤œè¨ã™ã‚‹ã€‚
- ç¶­æŒç®¡ç†ï¼šè»½å¾®æ®µéšã§ã®ç›®åœ°/é˜²æ°´è£œä¿®ãƒ»å†å¡—è£…ç­‰ãŒãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚³ã‚¹ãƒˆã‚’ä½æ¸›ã™ã‚‹ã€‚
- åˆ¤å®šã¯ã€Œç”»åƒæ‰€è¦‹ã€ã€ŒRAGæ ¹æ‹ ã€ã€Œç¾åœ°æ¡ä»¶ã€ã®æ•´åˆã§è¡Œã„ã€ä¸è¶³ãŒã‚ã‚Œã°â€œæœªç¢ºå®šâ€ã¨è¡¨ç¾ã™ã‚‹ã€‚
    """)

# ---------------------- Gemini API ----------------------
def image_to_inline_part(image: Image.Image, max_width: int = 1400) -> Dict:
    if image.mode != "RGB": image = image.convert("RGB")
    if image.width > max_width:
        r = max_width / float(image.width)
        image = image.resize((max_width, int(image.height * r)))
    buf = io.BytesIO()
    image.save(buf, format="JPEG", quality=90, optimize=True)
    b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
    return {"inline_data": {"mime_type": "image/jpeg", "data": b64}}

def call_gemini(api_key: str, prompt_text: str, image_parts: List[Dict]) -> Dict:
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}
    parts = [{"text": prompt_text}] + image_parts
    payload = {"contents": [{"parts": parts}]}
    resp = requests.post(url, headers=headers, json=payload, timeout=120)
    resp.raise_for_status()
    return resp.json()

def extract_text_from_gemini(result: Dict) -> str:
    try:
        return result["candidates"][0]["content"]["parts"][0]["text"]
    except Exception:
        return ""

# ---------------------- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ç«‹ ----------------------
def build_master_prompt(user_q: str, rag_snippets: List[Dict[str, Any]], priors: str,
                        vis_find: Optional[Dict[str, Any]], ir_find: Optional[Dict[str, Any]],
                        rule_grade: str, rule_life: str, ir_meta: Dict) -> str:
    rag_lines = []
    for d in rag_snippets:
        pg = f" p.{d['page_start']}" if d.get("page_start") is not None else ""
        rag_lines.append(f"[{d['doc']}{pg}] {d['text']}")
    rag_text = "\n".join(rag_lines) if rag_lines else "ï¼ˆè©²å½“æŠœç²‹ãªã—ï¼‰"

    vis_block = f"å¯è¦–ç”»åƒæ‰€è¦‹(ç°¡æ˜“):\n- metrics: {vis_find['metrics']}\n- crack_hint: {vis_find['crack_hint']}\n- stain_hint: {vis_find['stain_hint']}\n- screening_level: {vis_find['screening_level']}\n" if vis_find else ""
    ir_block = ""
    if ir_find:
        ir_block = f"""IRç”»åƒæ‰€è¦‹(ç›¸å¯¾):
- delta_rel(0-1): {ir_find['delta_rel']}, stdev: {ir_find['stdev']}, pattern: {ir_find['pattern']}
- æ³¨æ„: {ir_find['note']}
- ãƒ¡ã‚¿: Îµ={ir_meta.get('emissivity','ä¸æ˜')}, T_ref={ir_meta.get('t_ref','ä¸æ˜')}â„ƒ, T_amb={ir_meta.get('t_amb','ä¸æ˜')}â„ƒ, RH={ir_meta.get('rh','ä¸æ˜')}%, dist={ir_meta.get('dist','ä¸æ˜')}m, angle={ir_meta.get('angle','ä¸æ˜')}Â°
"""
    prompt = f"""
ã‚ãªãŸã¯éç ´å£Šæ¤œæŸ»ãƒ»å»ºç¯‰ãƒ»ææ–™å­¦ã®ä¸Šç´šè¨ºæ–­å£«ã€‚ä»¥ä¸‹ã®ææ–™ã ã‘ã‚’æ ¹æ‹ ã«ã€æ—¥æœ¬èªã§â€œçµæœã®ã¿â€ã®çŸ­ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã›ã‚ˆã€‚
**ç¦æ­¢**ï¼šæ¨æ¸¬ã§ã®æ•°å€¤åŒ–ãƒ»æœªå‡ºå…¸ã®é–¾å€¤è¨˜è¼‰ãƒ»ä¸€èˆ¬çŸ¥è­˜ã®ç„¡æ ¹æ‹ å¼•ç”¨ã€‚æ ¹æ‹ ãŒç„¡ã„é …ç›®ã¯ã€Œæœªæ²è¼‰/æœªç¢ºå®šã€ã¨ã™ã‚‹ã€‚
# å…¥åŠ›
- ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {user_q}
- RAGæŠœç²‹:
{rag_text}
- ãƒ‰ãƒ¡ã‚¤ãƒ³ä¸€èˆ¬åŸå‰‡:
{priors}
- ç”»åƒã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ‰€è¦‹:
{vis_block}{ir_block}
- ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æš«å®š:
  * æš«å®šã‚°ãƒ¬ãƒ¼ãƒ‰: {rule_grade}
  * å‚è€ƒå¯¿å‘½: {rule_life}
# å‡ºåŠ›ä»•æ§˜ï¼ˆMarkdownã€â€œçµæœã®ã¿â€ï¼‰
1. **ç·åˆè©•ä¾¡**ï¼ˆA/B/C/Dã€ä¸»å› 1â€“2è¡Œã€æš«å®šã‚’æ˜è¨˜å¯ï¼‰
2. **æ¨å®šæ®‹å­˜å¯¿å‘½**ï¼ˆå¹…ã€‚RAGã«æ ¹æ‹ ãŒç„¡ã‘ã‚Œã°ã€Œå‚è€ƒï¼ˆç”»åƒãƒ»ä¸€èˆ¬åŸå‰‡ãƒ™ãƒ¼ã‚¹ï¼‰ã€ã¨æ˜ç¤ºï¼‰
3. **ä¸»è¦æ ¹æ‹ **ï¼ˆå¯è¦–/IR/RAGã®é †ã§ç°¡æ½”ã€‚å„é …ç›®ã« [å‡ºå…¸] ã‚’ä»˜ä¸ã€‚æ•°å€¤ã¯RAGã«ã‚ã‚‹å ´åˆã®ã¿ï¼‰
4. **æ¨å¥¨å¯¾å¿œï¼ˆå„ªå…ˆåº¦é †ï¼‰**ï¼ˆå®‰å…¨å´ã€‚å‡ºå…¸ãŒã‚ã‚Œã°ä½µè¨˜ï¼‰
5. **é™ç•Œã¨è¿½åŠ ãƒ‡ãƒ¼ã‚¿è¦æœ›**ï¼ˆä¸è¶³æ ¹æ‹ ã€å¿…è¦ãªç¾åœ°ç¢ºèªãƒ»NDTï¼‰
æ³¨æ„ï¼šç”»åƒã®ã¿ã§ç¢ºå®šã§ããªã„é …ç›®ã¯æ–­å®šã—ãªã„ã€‚IR JPEGã¯ç›¸å¯¾åˆ¤æ–­ã«ç•™ã‚ã‚‹ã€‚
""".strip()
    return normalize_text(prompt)

# ---------------------- CSSï¼ˆå…ˆé€²UIãƒ‡ã‚¶ã‚¤ãƒ³ï¼‰ ----------------------
def inject_advanced_ui_css():
    components.v1.html("""
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&family=Noto+Sans+JP:wght@400;500;700;900&display=swap" rel="stylesheet">
<style id="advanced-ui-style">
:root {
    --font-sans: 'Inter', 'Noto Sans JP', sans-serif;
    --font-jp: 'Noto Sans JP', sans-serif;
    --primary-color: #0052D4;
    --secondary-color: #65C7F7;
    --accent-color: #9CECFB;
    --text-color: #E2E8F0;
    --bg-color: #0A101A;
    --surface-color: rgba(23, 29, 41, 0.5);
    --surface-border: rgba(255, 255, 255, 0.1);
    --outline-color: rgba(101, 199, 247, 0.6);
    --radius-lg: 24px; --radius-md: 16px; --radius-sm: 12px;
    --shadow-lg: 0 10px 30px rgba(0, 0, 0, 0.2);
    --shadow-md: 0 4px 15px rgba(0, 0, 0, 0.15);
    --tap-min: 48px;
}
body {
    background: var(--bg-color);
    background-image: linear-gradient(160deg, var(--bg-color) 0%, #111827 100%);
    font-family: var(--font-sans);
    color: var(--text-color);
}
.stApp { background: transparent; }
.block-container { padding: 1.5rem 1rem 3rem 1rem !important; max-width: 800px; margin: 0 auto; }
.app-header {
    text-align: center; margin-bottom: 2rem; padding: 1rem;
    background: rgba(0,0,0,0.2); border-radius: var(--radius-lg);
}
.app-header-title {
    font-family: 'Inter', sans-serif; font-weight: 800; font-size: 2.2rem; line-height: 1.2;
    background: linear-gradient(45deg, var(--accent-color), var(--secondary-color));
    -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin: 0;
}
.app-header-sub { font-size: 0.9rem; color: var(--text-color); opacity: 0.8; margin-top: 0.5rem; }
.step-card {
    background: var(--surface-color); border: 1px solid var(--surface-border);
    border-radius: var(--radius-lg); padding: 1.5rem; margin-bottom: 1.5rem;
    box-shadow: var(--shadow-lg); backdrop-filter: blur(16px); -webkit-backdrop-filter: blur(16px);
    transition: all 0.3s ease;
}
.step-card:hover { transform: translateY(-4px); box-shadow: 0 12px 40px rgba(0, 0, 0, 0.25); }
.step-title {
    display: flex; align-items: center; font-size: 1.2rem; font-weight: 700;
    color: var(--text-color); margin: 0 0 1rem 0;
    border-bottom: 1px solid var(--surface-border); padding-bottom: 0.75rem;
}
.step-title .icon { font-size: 1.5rem; margin-right: 0.75rem; line-height: 1; }
.stButton>button, .stTextInput input, .stFileUploader label, .stCameraInput label {
    border-radius: var(--radius-sm) !important; font-weight: 600; font-family: var(--font-sans);
    transition: all 0.2s ease; border: 1px solid var(--surface-border) !important;
    background: rgba(255, 255, 255, 0.05) !important; color: var(--text-color) !important;
    min-height: var(--tap-min);
}
.stFileUploader label, .stCameraInput label { display: flex; justify-content: center; align-items: center; text-align: center; }
.stButton>button {
    background: linear-gradient(90deg, var(--primary-color), var(--secondary-color)) !important;
    border: none !important; box-shadow: var(--shadow-md); font-weight: 700;
}
.stButton>button:hover { transform: scale(1.02); box-shadow: 0 0 20px rgba(101, 199, 247, 0.5); }
:where(button,input,select,textarea):focus-visible { outline: 3px solid var(--outline-color) !important; outline-offset: 2px; }
.stTextInput input { color: var(--text-color) !important; }
.image-preview-container { display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; }
.image-preview-container .stImage { border-radius: var(--radius-md); overflow: hidden; }
.report-card {
    background: var(--surface-color); border: 1px solid var(--surface-border);
    border-radius: var(--radius-lg); padding: 1.5rem 1.75rem; box-shadow: var(--shadow-lg);
    backdrop-filter: blur(16px); -webkit-backdrop-filter: blur(16px); font-family: var(--font-jp);
}
.report-card h1, .report-card h2, .report-card h3 { color: var(--accent-color); border-bottom: 1px solid var(--surface-border); padding-bottom: 0.5rem; margin-top: 1.5rem; }
.report-card strong { color: var(--secondary-color); }
.stExpander { border: 1px solid var(--surface-border) !important; border-radius: var(--radius-md) !important; background: rgba(255, 255, 255, 0.05) !important; }
.stFolium { border-radius: var(--radius-md); overflow: hidden; border: 1px solid var(--surface-border); }
</style>""", height=0)

# ---------------------- ä½ç½®ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯JSï¼‰ ----------------------
def geolocate_fallback_via_query_params(show_widget: bool = True) -> Tuple[Optional[float], Optional[float]]:
    params = st.query_params
    lat = params.get("lat")
    lon = params.get("lon")
    if lat and lon:
        try: return float(lat), float(lon)
        except Exception: return None, None
    if show_widget:
        components.v1.html("""
<script>
(function(){
  if (!navigator.geolocation){return;}
  navigator.geolocation.getCurrentPosition(function(pos){
    const lat = pos.coords.latitude.toFixed(6), lon = pos.coords.longitude.toFixed(6);
    const url = new URL(window.location.href);
    url.searchParams.set('lat', lat); url.searchParams.set('lon', lon);
    const a=document.createElement('a'); a.href=url.toString(); a.target='_top';
    document.body.appendChild(a); a.click();
  }, function(){}, {enableHighAccuracy:true, timeout:10000, maximumAge:0});
})();
</script>""", height=0)
    return None, None

# ---------------------- ãƒ¡ã‚¤ãƒ³ ----------------------
def main():
    st.set_page_config(page_title=APP_TITLE, layout="centered")
    inject_advanced_ui_css()

    st.markdown(f"""
<div class="app-header">
  <div class="app-header-title">ğŸ—ï¸ {APP_TITLE}</div>
  <div class="app-header-sub">AI Building Diagnostics</div>
</div>""", unsafe_allow_html=True)

    st.markdown('<div class="step-card"><div class="step-title"><span class="icon">ğŸ“</span>1. Diagnostic Query</div>', unsafe_allow_html=True)
    user_q = st.text_input("ä¾‹ï¼šå¤–å£ã‚¿ã‚¤ãƒ«ã®ã²ã³å‰²ã‚ŒåŸºæº–ã¨æ¨å®šå¯¿å‘½", "", placeholder="åˆ†æã—ãŸã„ãƒ†ãƒ¼ãƒãƒ»è³ªå•ã‚’å…¥åŠ›...", label_visibility="collapsed")
    st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<div class="step-card"><div class="step-title"><span class="icon">ğŸ“¸</span>2. Image Input (Visible / IR)</div>', unsafe_allow_html=True)
    colA, colB = st.columns(2)
    with colA:
        st.markdown("**Visible Image**")
        vis_file = st.file_uploader("Upload JPG/PNG", type=["jpg","jpeg","png"], key="vis_up")
        vis_cam  = st.camera_input("Take a Photo", key="vis_cam")
    with colB:
        st.markdown("**Infrared (IR) Image (Optional)**")
        ir_file = st.file_uploader("Upload IR JPG/PNG", type=["jpg","jpeg","png"], key="ir_up")
        with st.expander("IR Metadata (Optional)"):
            ir_emiss, ir_tref, ir_tamb = st.text_input("Emissivity Îµ", "0.95"), st.text_input("Ref. Temp T_ref[Â°C]", "20"), st.text_input("Amb. Temp T_amb[Â°C]", "22")
            ir_rh, ir_dist, ir_ang = st.text_input("RH[%]", "65"), st.text_input("Distance[m]", "5"), st.text_input("Angle[Â°]", "10")
    
    vis_img = Image.open(vis_cam) if vis_cam else (Image.open(vis_file) if vis_file else None)
    ir_img  = Image.open(ir_file) if ir_file else None

    if vis_img or ir_img:
        st.markdown('<div class="image-preview-container">', unsafe_allow_html=True)
        if vis_img: st.image(vis_img, caption="Visible Image", use_container_width=True)
        if ir_img: st.image(ir_img, caption="IR Image", use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<div class="step-card"><div class="step-title"><span class="icon">ğŸ“</span>3. Location (Auto or Manual)</div>', unsafe_allow_html=True)
    lat_val, lon_val = None, None
    if HAVE_GEO:
        loc = st_geolocation(key="geoloc", label="Get Current Location")
        if isinstance(loc, dict):
            try:
                lat_val, lon_val = float(loc.get("latitude")), float(loc.get("longitude"))
            except (TypeError, ValueError): pass
    else:
        st.info("ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæœªå°å…¥ã®ãŸã‚ç°¡æ˜“æ–¹å¼ã§ã™ã€‚")
        if st.button("ç¾åœ¨åœ°ã‚’å–å¾—ï¼ˆç°¡æ˜“ï¼‰"): geolocate_fallback_via_query_params(show_widget=True)
        lat_val, lon_val = geolocate_fallback_via_query_params(show_widget=False)
    
    c1, c2 = st.columns(2)
    lat_str = c1.text_input("Latitude", value=f"{lat_val:.6f}" if lat_val else "", key="lat_manual")
    lon_str = c2.text_input("Longitude", value=f"{lon_val:.6f}" if lon_val else "", key="lon_manual")
    
    try: lat_f, lon_f = (float(lat_str) if lat_str else None), (float(lon_str) if lon_str else None)
    except (TypeError, ValueError): lat_f, lon_f = None, None

    if lat_f is not None and lon_f is not None:
        m = folium.Map(location=[lat_f, lon_f], zoom_start=18, tiles="CartoDB positron")
        folium.Marker([lat_f, lon_f], tooltip="Target Location").add_to(m)
        st_folium(m, height=300, use_container_width=True)
    else:
        st.info("ç·¯åº¦çµŒåº¦ã‚’æŒ‡å®šã™ã‚‹ã¨åœ°å›³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    st.markdown('</div>', unsafe_allow_html=True)

    if st.button("ğŸš€ Analyze Now (RAG + Vision + AI)", use_container_width=True):
        if not user_q:
            st.error("ã‚¹ãƒ†ãƒƒãƒ—1ã§è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        with st.spinner("AIãŒåˆ†æä¸­ã§ã™..."):
            try:
                vis_find = analyze_visual(vis_img) if vis_img else None
                ir_meta = {"has_ir": ir_img is not None, "emissivity": ir_emiss, "t_ref": ir_tref, "t_amb": ir_tamb, "rh": ir_rh, "dist": ir_dist, "angle": ir_ang}
                ir_find = analyze_ir(ir_img, ir_meta) if ir_img else None
                rule_grade, rule_reason = rule_based_grade(vis_find, ir_find)
                rule_life = rule_based_life(rule_grade)
                snippets = rag_search(user_q, have_ir=ir_img is not None, k=MAX_SNIPPETS)
                priors = domain_priors_text()
                image_parts = [part for img in [vis_img, ir_img] if img and (part := image_to_inline_part(img))]
                prompt = build_master_prompt(user_q, snippets, priors, vis_find, ir_find, rule_grade, rule_life, ir_meta)
                
                api_key = st.secrets.get("gemini", {}).get("API_KEY")
                if not api_key:
                    st.error("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                    return
                
                result = call_gemini(api_key, prompt, image_parts)
                report_md = extract_text_from_gemini(result)
            
            except requests.HTTPError as e:
                st.error(f"APIã‚¨ãƒ©ãƒ¼: {e.response.status_code} {e.response.reason}\n{e.response.text[:500]}")
                return
            except Exception as e:
                st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                return

        if not report_md:
            st.warning("ãƒ¬ãƒãƒ¼ãƒˆãŒç©ºã§ã™ã€‚å…¥åŠ›ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
            return

        st.markdown('<div class="step-card" style="margin-top: 2rem;"><div class="step-title"><span class="icon">ğŸ“Š</span>5. Analysis Result</div></div>', unsafe_allow_html=True)
        try:
            summary_pattern = r"(?:^|\n)##?\s*ç·åˆè©•ä¾¡[\s\S]*?(?=\n##?\s|\Z)"
            summary_match = re.search(summary_pattern, report_md, re.IGNORECASE)
            summary_block = summary_match.group(0) if summary_match else None
        except Exception:
            summary_block = None

        if summary_block:
            st.markdown(f'<div class="report-card">{summary_block}</div>', unsafe_allow_html=True)

        with st.expander("è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã¨è¨ºæ–­æ ¹æ‹ ã‚’è¡¨ç¤º", expanded=(not summary_block)):
            st.markdown('<div class="report-card" style="margin-top: 1rem;">', unsafe_allow_html=True)
            st.markdown(f"**ï¼ˆå‚è€ƒï¼‰ç”»åƒï¼‹ä¸€èˆ¬åŸå‰‡ã«ã‚ˆã‚‹æš«å®šè©•ä¾¡**\n- **ã‚°ãƒ¬ãƒ¼ãƒ‰:** `{rule_grade}` ({rule_reason})\n- **å‚è€ƒå¯¿å‘½:** `{rule_life}`\n---")
            st.markdown(report_md, unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        st.download_button("ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", report_md, "building_report.md", "text/markdown", use_container_width=True)

    st.caption("Â© å»ºç‰©è¨ºæ–­ãã‚“ â€” AI Building Diagnostics with Gemini 2.5 Flash.")

if __name__ == "__main__":
    main()
