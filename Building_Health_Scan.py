# -*- coding: utf-8 -*-
"""
å»ºç‰©è¨ºæ–­ãã‚“ Pro (Refactored Ultimate Edition)
Author: World Class Program Designer
Date: 2026-01-20
Description: RAG-based Building Diagnosis System with Multi-modal Analysis
"""

import os
import io
import re
import math
import base64
import statistics
import unicodedata
import time
import pkgutil
from datetime import date
from typing import List, Tuple, Dict, Any, Set, Optional

# --- Streamlit & Visualization ---
import streamlit as st
import streamlit.components.v1 as components
from streamlit_folium import st_folium
import folium

# --- Data & Processing ---
import requests
import PyPDF2
from PIL import Image, ImageFilter, ImageOps

# --- Optional Dependencies ---
HAVE_BACK_CAM = False
try:
    from streamlit_back_camera_input import back_camera_input
    HAVE_BACK_CAM = True
except ImportError:
    pass

# Patch for older environments
if not hasattr(pkgutil, "ImpImporter"):
    pkgutil.ImpImporter = pkgutil.zipimporter

# ===========================================================
# 1. Configuration & Constants
# ===========================================================

class Config:
    APP_TITLE = "å»ºç‰©è¨ºæ–­ãã‚“ Pro"
    APP_VERSION = "3.0.0 Ultimate"
    
    # UI Colors (Light Theme for Map Visibility)
    COLOR_PRIMARY = "#0066CC"  # Architectural Blue
    COLOR_BG = "#F4F6F9"       # Light Slate
    COLOR_CARD = "#FFFFFF"
    
    # System Limits
    MAX_SNIPPETS = 8
    MAX_SNIPPET_CHARS = 1200
    MAX_IMAGES_TOTAL = 16
    
    # PDF Sources
    PDF_SOURCES = [
        ("Structure_Base.pdf", "Structure_Base.pdf"),
        ("ä¸Šå³¶ç”º å…¬å…±æ–½è¨­ç­‰ç·åˆç®¡ç†è¨ˆç”»", "kamijimachou_Public_facility_management_plan.pdf"),
        ("æ¸¯åŒº å…¬å…±æ–½è¨­ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆè¨ˆç”»", "minatoku_Public_facility_management_plan.pdf"),
    ]
    
    DOC_TYPES = {
        "Structure_Base.pdf": "åŸºæº–",
        "kamijimachou_Public_facility_management_plan.pdf": "è¨ˆç”»",
        "minatoku_Public_facility_management_plan.pdf": "è¨ˆç”»",
    }

    # Diagnosis Dictionaries
    QUERY_SYNONYMS = {
        "ã²ã³å‰²ã‚Œ": ["ã²ã³å‰²ã‚Œ", "ã‚¯ãƒ©ãƒƒã‚¯", "äº€è£‚", "ã²ã³", "ãƒ˜ã‚¢ã‚¯ãƒ©ãƒƒã‚¯"],
        "æµ®ã": ["æµ®ã", "ã†ã", "å‰¥é›¢äºˆå…†"],
        "å‰¥é›¢": ["å‰¥é›¢", "ã¯ãé›¢", "ã¯ãã‚Š", "æ¬ æ", "è½ä¸‹"],
        "æ¼æ°´": ["å«æ°´", "æµ¸æ°´", "æ¼æ°´", "é›¨æ°´ä¾µå…¥", "é›¨æ¼ã‚Š", "ã‚¨ãƒ•ãƒ­"],
        "èµ¤å¤–ç·š": ["èµ¤å¤–ç·š", "IR", "ã‚µãƒ¼ãƒ¢", "ç†±ç”»åƒ", "æ¸©åº¦å·®"],
        "åŸºæº–": ["åŸºæº–", "åˆ¤å®š", "è©•ä¾¡", "é–¾å€¤", "è¨±å®¹å€¤", "ç®¡ç†å€¤"],
        "é˜²æ°´": ["é˜²æ°´", "å¡—è†œ", "ã‚·ãƒ¼ãƒªãƒ³ã‚°", "ã‚·ãƒ¼ãƒ«", "ã‚¢ã‚¹ãƒ•ã‚¡ãƒ«ãƒˆ", "ã‚·ãƒ¼ãƒˆé˜²æ°´"],
    }

    MATERIAL_KEYWORDS = {
        "ã‚¿ã‚¤ãƒ«": ["ã‚¿ã‚¤ãƒ«", "ç£å™¨è³ª", "å¤–å£ã‚¿ã‚¤ãƒ«", "ç›®åœ°"],
        "ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ": ["ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ", "RC", "èº¯ä½“", "ãƒ¢ãƒ«ã‚¿ãƒ«"],
        "é˜²æ°´ã‚·ãƒ¼ãƒˆ": ["é˜²æ°´ã‚·ãƒ¼ãƒˆ", "å¡©ãƒ“", "ã‚´ãƒ ã‚·ãƒ¼ãƒˆ", "ã‚¢ã‚¹ãƒ•ã‚¡ãƒ«ãƒˆé˜²æ°´"],
        "ã‚·ãƒ¼ãƒªãƒ³ã‚°": ["ã‚·ãƒ¼ãƒªãƒ³ã‚°", "ã‚³ãƒ¼ã‚­ãƒ³ã‚°", "ã‚·ãƒ¼ãƒ«"],
    }

    DEFECT_KEYWORDS = {
        "ã²ã³å‰²ã‚Œ": ["ã²ã³å‰²ã‚Œ", "ã‚¯ãƒ©ãƒƒã‚¯", "äº€è£‚"],
        "æµ®ã": ["æµ®ã", "ã†ã"],
        "å‰¥é›¢": ["å‰¥é›¢", "æ¬ æ", "è½ä¸‹"],
        "æ¼æ°´": ["æ¼æ°´", "é›¨æ¼ã‚Š", "ã‚¨ãƒ•ãƒ­ãƒ¬ãƒƒã‚»ãƒ³ã‚¹", "ç™½è¯"],
    }

    TEMPLATES = {
        "å¤–å£ï¼ˆã‚¿ã‚¤ãƒ«ï¼‰": {
            "tags": ["ã‚¿ã‚¤ãƒ«", "å£", "ã‚·ãƒ¼ãƒªãƒ³ã‚°"],
            "checklist": ["å…¨æ™¯ï¼ˆå»ºç‰©å…¨ä½“ï¼‰", "ä¸­æ™¯ï¼ˆç—‡çŠ¶ç®‡æ‰€ï¼‰", "è¿‘æ™¯ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«å…¥ï¼‰", "æ‰“è¨ºä½ç½®ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰"],
            "mode": "strict"
        },
        "å£ï¼ˆä»•ä¸Šã’ãƒ»èº¯ä½“ï¼‰": {
            "tags": ["å£", "ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ", "ã‚·ãƒ¼ãƒªãƒ³ã‚°"],
            "checklist": ["å…¨æ™¯", "ã²ã³å‰²ã‚ŒçŠ¶æ³", "ã‚¨ãƒ•ãƒ­æœ‰ç„¡", "é›¨æ›ã‹ã‚ŠçŠ¶æ³"],
            "mode": "strict"
        },
        "å±‹ä¸Šï¼ˆé˜²æ°´ã‚·ãƒ¼ãƒˆï¼‰": {
            "tags": ["é˜²æ°´ã‚·ãƒ¼ãƒˆ", "ãƒ‰ãƒ¬ãƒ³", "ç«¯éƒ¨", "ç«‹ä¸Šã‚Š"],
            "checklist": ["å…¨æ™¯ï¼ˆå‹¾é…ï¼‰", "ã‚·ãƒ¼ãƒˆç¶™ãç›®", "ãƒ‰ãƒ¬ãƒ³å‘¨è¾º", "ç«‹ä¸Šã‚Šç«¯éƒ¨"],
            "mode": "maintenance"
        },
    }

# ===========================================================
# 2. Advanced Utilities (Text & Image)
# ===========================================================

class Utils:
    @staticmethod
    def normalize_text(text: str) -> str:
        text = unicodedata.normalize("NFKC", text)
        text = re.sub(r"[\r\n]+", " ", text)
        return re.sub(r"\s+", " ", text).strip()

    @staticmethod
    def tokenize(text: str) -> List[str]:
        text = text.lower()
        text = re.sub(r"[^\wä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³ï¼…â„ƒ\.]", " ", text)
        return text.split()

    @staticmethod
    def expand_query(query: str) -> List[str]:
        tokens = set(Utils.tokenize(query))
        for key, syns in Config.QUERY_SYNONYMS.items():
            if key in query or any(s in query for s in syns):
                for s in syns:
                    tokens.update(Utils.tokenize(s))
        return list(tokens)

    @staticmethod
    def fix_image_orientation(image: Image.Image) -> Image.Image:
        """Fix EXIF orientation for smartphone photos"""
        try:
            return ImageOps.exif_transpose(image)
        except Exception:
            return image

class ImageAnalyzer:
    @staticmethod
    def get_stats(image: Image.Image, size: int = 256) -> Dict[str, float]:
        if image.mode != "RGB":
            image = image.convert("RGB")
        
        # Resize for performance
        w = size if image.width > size else image.width
        h = int(image.height * (w / image.width))
        img_small = image.resize((w, h))
        
        gray = img_small.convert("L")
        pixels = list(gray.getdata())
        
        # Statistics
        mean_l = statistics.mean(pixels) if pixels else 0
        
        # Edge detection
        edges = gray.filter(ImageFilter.FIND_EDGES)
        edge_pixels = list(edges.getdata())
        strong_edges = sum(1 for x in edge_pixels if x > 60)
        edge_ratio = strong_edges / len(edge_pixels) if edge_pixels else 0
        
        return {
            "mean_l": mean_l,
            "edge_ratio": edge_ratio,
            "width": image.width,
            "height": image.height
        }

    @staticmethod
    def analyze(image: Image.Image, is_ir: bool = False, meta: Dict = None) -> Dict[str, Any]:
        stats = ImageAnalyzer.get_stats(image)
        result = {"stats": stats, "meta": meta or {}, "type": "IR" if is_ir else "Visual"}
        
        if is_ir:
            result["note"] = "èµ¤å¤–ç·šç”»åƒ: ç›¸å¯¾æ¸©åº¦å·®ã®è§£æãŒå¿…è¦ã§ã™ã€‚"
            # IR-specific simple logic could go here
        else:
            # Visual Logic
            if stats["edge_ratio"] > 0.20:
                result["hint"] = "é«˜å¯†åº¦ã‚¨ãƒƒã‚¸æ¤œå‡º (ã²ã³å‰²ã‚Œã¾ãŸã¯è¤‡é›‘ãªãƒ†ã‚¯ã‚¹ãƒãƒ£)"
            elif stats["mean_l"] < 80:
                result["hint"] = "ä½è¼åº¦ (æš—æ‰€ã¾ãŸã¯æ±šã‚Œ)"
            else:
                result["hint"] = "ç‰¹ç•°ãªç•°å¸¸å€¤ãªã— (ç”»åƒçµ±è¨ˆ)"
                
        return result

    @staticmethod
    def to_gemini_part(image: Image.Image, max_dim: int = 1536) -> Dict:
        if image.mode != "RGB":
            image = image.convert("RGB")
        
        # Smart resize
        if max(image.width, image.height) > max_dim:
            image.thumbnail((max_dim, max_dim), Image.LANCZOS)
            
        buf = io.BytesIO()
        image.save(buf, format="JPEG", quality=85, optimize=True)
        return {
            "inline_data": {
                "mime_type": "image/jpeg",
                "data": base64.b64encode(buf.getvalue()).decode("utf-8")
            }
        }

# ===========================================================
# 3. High-Performance RAG Engine
# ===========================================================

class BM25Index:
    def __init__(self, k1=1.5, b=0.75):
        self.k1 = k1
        self.b = b
        self.docs = []
        self.avgdl = 0
        self.doc_freqs = []
        self.idf = {}
        self.N = 0

    def fit(self, docs: List[Dict[str, Any]]):
        self.docs = docs
        self.N = len(docs)
        self.doc_freqs = []
        df_counter = {}
        total_len = 0

        for doc in docs:
            tokens = doc["_tokens"]
            length = len(tokens)
            total_len += length
            
            freqs = {}
            for t in tokens:
                freqs[t] = freqs.get(t, 0) + 1
            self.doc_freqs.append((length, freqs))
            
            for t in freqs.keys():
                df_counter[t] = df_counter.get(t, 0) + 1
        
        self.avgdl = total_len / self.N if self.N > 0 else 0
        for t, freq in df_counter.items():
            self.idf[t] = math.log(1 + (self.N - freq + 0.5) / (freq + 0.5))

    def search(self, query_tokens: List[str], top_k: int = 5) -> List[Tuple[float, int]]:
        scores = []
        for idx, (doc_len, freqs) in enumerate(self.doc_freqs):
            score = 0.0
            for t in query_tokens:
                if t not in freqs: continue
                idf = self.idf.get(t, 0)
                tf = freqs[t]
                num = tf * (self.k1 + 1)
                den = tf + self.k1 * (1 - self.b + self.b * (doc_len / (self.avgdl or 1)))
                score += idf * (num / den)
            if score > 0:
                scores.append((score, idx))
        
        scores.sort(key=lambda x: x[0], reverse=True)
        return scores[:top_k]

class RAGEngine:
    _instance = None
    
    def __init__(self):
        self.index = BM25Index()
        self.chunks = []
        self.ready = False

    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    def load_documents(self):
        if self.ready: return
        
        chunks = []
        for filename, path in Config.PDF_SOURCES:
            if not os.path.exists(path):
                # Fallback: Create dummy chunk if file missing
                chunks.append({
                    "text": f"Error: {filename} not found. Running in simulation mode.",
                    "doc": filename,
                    "doc_type": "System",
                    "page": 0,
                    "_tokens": ["error", "system"]
                })
                continue

            try:
                reader = PyPDF2.PdfReader(path)
                base_name = os.path.basename(path)
                doc_type = Config.DOC_TYPES.get(base_name, "ãã®ä»–")
                
                for i, page in enumerate(reader.pages):
                    text = Utils.normalize_text(page.extract_text() or "")
                    if len(text) < 10: continue
                    
                    # Splitting into overlapping chunks
                    step = 800
                    overlap = 100
                    for start in range(0, len(text), step - overlap):
                        end = min(start + step, len(text))
                        sub_text = text[start:end]
                        if len(sub_text) > 50:
                            chunks.append({
                                "text": sub_text,
                                "doc": base_name,
                                "doc_type": doc_type,
                                "page": i + 1,
                                "_tokens": Utils.tokenize(sub_text),
                                "_has_num": bool(re.search(r"\d", sub_text))
                            })
            except Exception as e:
                print(f"Error reading {path}: {e}")

        self.chunks = chunks
        if chunks:
            self.index.fit(chunks)
        self.ready = True

    def query(self, user_query: str, filters: Dict[str, float], top_k: int = 5) -> List[Dict]:
        if not self.ready: self.load_documents()
        
        q_tokens = Utils.expand_query(user_query)
        raw_results = self.index.search(q_tokens, top_k=top_k * 2) # Get more candidates
        
        # Re-ranking / Weighting
        weighted_results = []
        for score, idx in raw_results:
            doc = self.chunks[idx]
            final_score = score
            
            # Boosters
            if doc["doc_type"] == "åŸºæº–":
                final_score *= filters.get("base_boost", 1.2)
            if doc["doc_type"] == "è¨ˆç”»":
                final_score *= filters.get("plan_boost", 1.1)
            if doc["_has_num"]:
                final_score *= filters.get("num_boost", 1.1)
            
            weighted_results.append((final_score, doc))
            
        weighted_results.sort(key=lambda x: x[0], reverse=True)
        return [item[1] for item in weighted_results[:top_k]]

# ===========================================================
# 4. API & Prompt Logic
# ===========================================================

def generate_diagnosis(api_key: str, query: str, context_docs: List[Dict], images: Dict[str, List[Image.Image]]) -> str:
    # 1. Prepare RAG Context
    rag_text = ""
    for i, doc in enumerate(context_docs, 1):
        rag_text += f"[å‡ºå…¸{i}: {doc['doc']} ({doc['doc_type']}) p.{doc['page']}]\n{doc['text'][:800]}...\n\n"
    
    if not rag_text: rag_text = "(é–¢é€£æ–‡çŒ®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ä¸€èˆ¬åŸå‰‡ã«åŸºã¥ã„ã¦å›ç­”ã—ã¾ã™ã€‚)"

    # 2. Prepare Images
    gemini_parts = [{"text": f"""
# å½¹å‰²
ã‚ãªãŸã¯æ—¥æœ¬æœ€é«˜å³°ã®å»ºç¯‰æ§‹é€ ãƒ»éç ´å£Šæ¤œæŸ»ã®å°‚é–€å®¶AIã§ã™ã€‚
å›½åœŸäº¤é€šçœã®åŸºæº–ã€ãŠã‚ˆã³æ·»ä»˜ã®æ–‡çŒ®ï¼ˆRAGãƒ‡ãƒ¼ã‚¿ï¼‰ã«åŸºã¥ãã€å³æ ¼ã‹ã¤è«–ç†çš„ãªè¨ºæ–­ã‚’è¡Œã„ã¾ã™ã€‚

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¾é ¼
ã€Œ{query}ã€

# å‚ç…§æ–‡çŒ®ãƒ‡ãƒ¼ã‚¿ (äº‹å®Ÿã®æ ¹æ‹ )
{rag_text}

# è¨ºæ–­ãƒãƒªã‚·ãƒ¼
1. **å®‰å…¨æ€§æœ€å„ªå…ˆ**: å†™çœŸã ã‘ã§æ–­å®šã§ããªã„å ´åˆã¯ã€Œç–‘ã„ã‚ã‚Šã€ã€Œè¦è©³ç´°èª¿æŸ»ã€ã¨ã—ã€å®‰å…¨å´ã®åˆ¤æ–­ã‚’è¡Œã†ã€‚
2. **æ ¹æ‹ ã®æ˜ç¤º**: åˆ¤æ–­ã«ã¯å¿…ãš[å‡ºå…¸X]ã‚’å¼•ç”¨ã™ã‚‹ã€‚
3. **é¡•å¾®é¡åˆ†æ**: é¡•å¾®é¡ç”»åƒãŒã‚ã‚‹å ´åˆã€ãƒã‚¤ã‚¯ãƒ­ã‚¯ãƒ©ãƒƒã‚¯ã‚„ã‚¨ãƒ•ãƒ­ãƒ¬ãƒƒã‚»ãƒ³ã‚¹ã®çµæ™¶æ§‹é€ ã«ã¤ã„ã¦è¨€åŠã™ã‚‹ã€‚
4. **æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: ç·Šæ€¥åº¦åˆ¤å®šã¨å…±ã«ã€å…·ä½“çš„ãªæ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ‰“è¨ºèª¿æŸ»ã€èµ¤å¤–ç·šèª¿æŸ»ç­‰ï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚

# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
Markdownå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""}]

    # Attach images with labels in prompt context (Gemini multimodal handles interleaved, but batch is easier)
    all_imgs = []
    if images["micro"]:
        gemini_parts.append({"text": "\n\nã€é¡•å¾®é¡ç”»åƒ (è©³ç´°è§£æç”¨)ã€‘:\n"})
        for img in images["micro"]: all_imgs.append(ImageAnalyzer.to_gemini_part(img))
    
    if images["ir"]:
        gemini_parts.append({"text": "\n\nã€èµ¤å¤–ç·šã‚µãƒ¼ãƒ¢ã‚°ãƒ©ãƒ•ã‚£ (æ¸©åº¦åˆ†å¸ƒ)ã€‘:\n"})
        for img in images["ir"]: all_imgs.append(ImageAnalyzer.to_gemini_part(img))
        
    if images["vis"]:
        gemini_parts.append({"text": "\n\nã€å¯è¦–ç”»åƒ (å…¨ä½“ãƒ»è¿‘æ™¯)ã€‘:\n"})
        for img in images["vis"]: all_imgs.append(ImageAnalyzer.to_gemini_part(img))
        
    # Merge text and images
    payload_parts = gemini_parts + all_imgs if all_imgs else gemini_parts

    # 3. Call API
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={api_key}"
    try:
        resp = requests.post(url, json={"contents": [{"parts": payload_parts}]}, headers={"Content-Type": "application/json"}, timeout=120)
        resp.raise_for_status()
        return resp.json()["candidates"][0]["content"]["parts"][0]["text"]
    except Exception as e:
        return f"è¨ºæ–­ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

# ===========================================================
# 5. UI Components & CSS
# ===========================================================

def load_custom_css():
    st.markdown(f"""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700&display=swap');
    
    html, body, [class*="css"] {{
        font-family: 'Noto Sans JP', -apple-system, BlinkMacSystemFont, sans-serif;
        color: #2c3e50;
        background-color: {Config.COLOR_BG};
    }}
    
    /* Card Style - Glassmorphism Lite */
    .app-card {{
        background: rgba(255, 255, 255, 0.95);
        border-radius: 12px;
        padding: 24px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.05), 0 2px 4px -1px rgba(0, 0, 0, 0.03);
        border: 1px solid rgba(255,255,255,0.5);
        margin-bottom: 20px;
        backdrop-filter: blur(10px);
    }}
    
    .card-title {{
        font-size: 1.25rem;
        font-weight: 700;
        color: {Config.COLOR_PRIMARY};
        margin-bottom: 1.0rem;
        border-bottom: 2px solid #f1f5f9;
        padding-bottom: 0.5rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }}
    
    /* Header */
    .hero-section {{
        background: linear-gradient(120deg, #0066CC 0%, #003366 100%);
        color: white;
        padding: 2rem 2rem;
        border-radius: 16px;
        margin-bottom: 2rem;
        box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1);
    }}
    
    .stTabs [data-baseweb="tab-list"] {{
        gap: 8px;
        background-color: transparent;
    }}
    
    .stTabs [data-baseweb="tab"] {{
        height: 48px;
        border-radius: 8px;
        background-color: white;
        border: 1px solid #e2e8f0;
        color: #64748b;
        font-weight: 600;
    }}
    
    .stTabs [aria-selected="true"] {{
        background-color: {Config.COLOR_PRIMARY};
        color: white;
        border: none;
        box-shadow: 0 4px 6px rgba(37, 99, 235, 0.2);
    }}

    /* Buttons */
    .stButton > button {{
        width: 100%;
        border-radius: 8px;
        font-weight: bold;
        transition: all 0.2s;
    }}
    
    /* Gallery Grid */
    .gallery-img {{
        border-radius: 8px;
        border: 2px solid #e2e8f0;
        transition: transform 0.2s;
    }}
    .gallery-img:hover {{
        border-color: {Config.COLOR_PRIMARY};
    }}
    </style>
    """, unsafe_allow_html=True)

def render_header():
    st.markdown(f"""
    <div class="hero-section">
        <h1 style="margin:0; font-size: 2.2rem;">ğŸ—ï¸ {Config.APP_TITLE}</h1>
        <p style="margin:0.5rem 0 0 0; opacity: 0.9; font-size: 1.0rem;">
            Ver {Config.APP_VERSION} | AI x é¡•å¾®é¡ x èµ¤å¤–ç·š ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ 
        </p>
    </div>
    """, unsafe_allow_html=True)

# ===========================================================
# 6. Main Application Logic
# ===========================================================

def main():
    st.set_page_config(page_title=Config.APP_TITLE, layout="wide", initial_sidebar_state="expanded")
    load_custom_css()
    
    # --- Session State Initialization ---
    if "images" not in st.session_state:
        st.session_state.images = {"vis": [], "ir": [], "micro": []}
    
    # --- Sidebar ---
    with st.sidebar:
        st.markdown("### âš™ï¸ è¨­å®š")
        st.info("ğŸ’¡ **Tips**: åœ°å›³ãŒè¦‹ã‚„ã™ã„ãƒ©ã‚¤ãƒˆãƒ†ãƒ¼ãƒã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚")
        
        api_key = st.text_input("Gemini API Key", type="password", help="Google AI Studioã§å–å¾—ã—ãŸã‚­ãƒ¼")
        if not api_key and "gemini" in st.secrets:
            api_key = st.secrets["gemini"]["API_KEY"]
            
        use_rag = st.toggle("RAG (æ–‡çŒ®æ¤œç´¢) ã‚’æœ‰åŠ¹åŒ–", value=True)
        
        st.divider()
        st.caption("Status:")
        if api_key: st.success("API Key: Ready") 
        else: st.error("API Key: Missing")
        
        rag_engine = RAGEngine.get_instance()
        if use_rag:
            with st.spinner("çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                rag_engine.load_documents()
            st.success(f"Docs: {len(rag_engine.chunks)} chunks")

    render_header()

    # --- Main Layout ---
    tab_diagnosis, tab_upload, tab_map = st.tabs(["ğŸ“‹ è¨ºæ–­è¨­å®š & çµæœ", "ğŸ“· ç”»åƒç™»éŒ²", "ğŸ“ ä½ç½®æƒ…å ±"])

    # 1. Image Upload Tab
    with tab_upload:
        st.markdown('<div class="app-card">', unsafe_allow_html=True)
        st.markdown('<div class="card-title">ğŸ“¥ ç”»åƒã‚¤ãƒ³ãƒãƒ¼ãƒˆ</div>', unsafe_allow_html=True)
        
        u_col1, u_col2 = st.columns([1, 1])
        
        with u_col1:
            img_type = st.radio("ç”»åƒç¨®åˆ¥", ["å¯è¦–ç”»åƒ (Visual)", "èµ¤å¤–ç·š (IR)", "é¡•å¾®é¡ (Microscope)"], horizontal=True)
            target_key = "vis" if "å¯è¦–" in img_type else ("ir" if "èµ¤å¤–ç·š" in img_type else "micro")
            
            # Input methods
            cam_val = st.camera_input("ã‚«ãƒ¡ãƒ©æ’®å½±")
            file_val = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ", accept_multiple_files=True, type=["jpg", "png", "jpeg"])
            
            # Processing
            new_imgs = []
            if cam_val: new_imgs.append(Image.open(cam_val))
            if file_val: 
                for f in file_val: new_imgs.append(Image.open(f))
                
            if new_imgs:
                for img in new_imgs:
                    img = Utils.fix_image_orientation(img)
                    st.session_state.images[target_key].append(img)
                st.toast(f"{len(new_imgs)}æšã®ç”»åƒã‚’è¿½åŠ ã—ã¾ã—ãŸ", icon="âœ…")
                
                # Keep gallery size inside limits
                total = sum(len(v) for v in st.session_state.images.values())
                if total > Config.MAX_IMAGES_TOTAL:
                    st.warning("ç”»åƒæšæ•°ãŒä¸Šé™ã‚’è¶…ãˆãŸãŸã‚ã€å¤ã„ç”»åƒã‹ã‚‰å‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚")

        with u_col2:
            st.markdown(f"**ã‚®ãƒ£ãƒ©ãƒªãƒ¼ ({sum(len(v) for v in st.session_state.images.values())}æš)**")
            if st.button("ğŸ—‘ï¸ å…¨ç”»åƒã‚’ã‚¯ãƒªã‚¢"):
                st.session_state.images = {"vis": [], "ir": [], "micro": []}
                st.rerun()
                
            for k, label in [("vis", "å¯è¦–"), ("ir", "èµ¤å¤–ç·š"), ("micro", "é¡•å¾®é¡")]:
                if st.session_state.images[k]:
                    st.caption(f"â–¼ {label}")
                    cols = st.columns(4)
                    for i, img in enumerate(st.session_state.images[k]):
                        with cols[i % 4]:
                            st.image(img, use_container_width=True)
                            
        st.markdown('</div>', unsafe_allow_html=True)

    # 2. Map Tab
    with tab_map:
        st.markdown('<div class="app-card">', unsafe_allow_html=True)
        st.markdown('<div class="card-title">ğŸ“ å¯¾è±¡æ–½è¨­ã®ä½ç½®</div>', unsafe_allow_html=True)
        
        m_col1, m_col2 = st.columns([1, 3])
        with m_col1:
            lat = st.number_input("ç·¯åº¦", value=35.6895, format="%.6f")
            lng = st.number_input("çµŒåº¦", value=139.6917, format="%.6f")
            st.info("åœ°å›³ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã—ã¦ä½ç½®ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        with m_col2:
            m = folium.Map(location=[lat, lng], zoom_start=17)
            folium.Marker([lat, lng], popup="è¨ºæ–­å¯¾è±¡", icon=folium.Icon(color="blue", icon="info-sign")).add_to(m)
            st_folium(m, height=400, use_container_width=True)
            
        st.markdown('</div>', unsafe_allow_html=True)

    # 3. Diagnosis Tab (Main)
    with tab_diagnosis:
        # Conditions
        st.markdown('<div class="app-card">', unsafe_allow_html=True)
        st.markdown('<div class="card-title">ğŸ“ è¨ºæ–­ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</div>', unsafe_allow_html=True)
        
        c_col1, c_col2 = st.columns(2)
        with c_col1:
            template = st.selectbox("è¨ºæ–­ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", list(Config.TEMPLATES.keys()))
            condition = st.text_input("å…·ä½“çš„ãªç—‡çŠ¶ãƒ»æ‡¸å¿µç‚¹", placeholder="ä¾‹ï¼šåŒ—é¢3éšã®å¤–å£ã‚¿ã‚¤ãƒ«ã«æµ®ããŒè¦‹ã‚‰ã‚Œã‚‹ã€‚")
        with c_col2:
            opts = st.multiselect("é‡ç‚¹ãƒã‚§ãƒƒã‚¯é …ç›®", ["åŸºæº–é©åˆæ€§", "ç·Šæ€¥åº¦åˆ¤å®š", "æ”¹ä¿®å·¥æ³•ææ¡ˆ", "ã‚³ã‚¹ãƒˆæ¦‚ç®—(LCC)"], default=["åŸºæº–é©åˆæ€§", "ç·Šæ€¥åº¦åˆ¤å®š"])
        
        if st.button("ğŸš€ AIè¨ºæ–­ã‚’å®Ÿè¡Œ (Pro Mode)", type="primary"):
            if not api_key:
                st.error("API Keyã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("AIãŒæ€è€ƒä¸­... ç”»åƒè§£æã¨æ–‡çŒ®ç…§åˆã‚’è¡Œã£ã¦ã„ã¾ã™..."):
                    # Build Query
                    tmpl_data = Config.TEMPLATES[template]
                    full_query = f"å¯¾è±¡: {template}ã€‚çŠ¶æ³: {condition}ã€‚é‡ç‚¹: {', '.join(opts)}ã€‚"
                    
                    # RAG Search
                    rag_docs = []
                    if use_rag:
                        filters = {"base_boost": 1.5, "num_boost": 1.2}
                        rag_docs = rag_engine.query(full_query, filters=filters, top_k=6)
                    
                    # Gemini Call
                    result = generate_diagnosis(api_key, full_query, rag_docs, st.session_state.images)
                    
                    # Store result
                    st.session_state["last_result"] = result
                    st.session_state["last_rag"] = rag_docs
        
        st.markdown('</div>', unsafe_allow_html=True)

        # Result Display
        if "last_result" in st.session_state:
            st.markdown('<div class="app-card" style="border-left: 5px solid #0066CC;">', unsafe_allow_html=True)
            st.markdown('<div class="card-title">ğŸ“Š è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ</div>', unsafe_allow_html=True)
            
            st.markdown(st.session_state["last_result"])
            
            st.divider()
            with st.expander("ğŸ“š å‚ç…§ã—ãŸæ–‡çŒ®æ ¹æ‹  (Evidence Chain)"):
                for d in st.session_state["last_rag"]:
                    st.markdown(f"**{d['doc']}** (p.{d['page']})")
                    st.caption(d['text'])
                    st.markdown("---")
            
            st.markdown('</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()
