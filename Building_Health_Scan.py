# -*- coding: utf-8 -*-
# ===========================================================
# å»ºç‰©è¨ºæ–­ãã‚“ Proï¼ˆå£ãƒ»ã‚¿ã‚¤ãƒ«ãƒ»é˜²æ°´ã‚·ãƒ¼ãƒˆç‰¹åŒ– / RAGåˆ¶å¾¡ / é¡•å¾®é¡çµ±åˆç‰ˆï¼‰
# Refactored by World Class Programmer
# ===========================================================

import pkgutil
# ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ã®ãƒ‘ãƒƒãƒ
if not hasattr(pkgutil, "ImpImporter"):
    pkgutil.ImpImporter = pkgutil.zipimporter

import os
import io
import re
import math
import base64
import statistics
import unicodedata
import time
from datetime import date
from typing import List, Tuple, Dict, Optional, Any, Set

import streamlit as st
import requests
import PyPDF2
from PIL import Image, ImageFilter

import folium
from streamlit_folium import st_folium
import streamlit.components.v1 as components

# --- Optional Dependencies ---
HAVE_BACK_CAM = False
try:
    from streamlit_back_camera_input import back_camera_input
    HAVE_BACK_CAM = True
except ImportError:
    pass

# ===========================================================
# 1. Config & Constants
# ===========================================================

APP_TITLE = "å»ºç‰©è¨ºæ–­ãã‚“ Pro"
APP_VERSION = "2.1.0 (Microscope Edition)"

# PDFã‚½ãƒ¼ã‚¹å®šç¾©ï¼ˆãŠæ‰‹å…ƒã®PDFãƒ•ã‚¡ã‚¤ãƒ«åã«åˆã‚ã›ã¦ãã ã•ã„ï¼‰
PDF_SOURCES = [
    ("Structure_Base.pdf", "Structure_Base.pdf"),
    ("ä¸Šå³¶ç”º å…¬å…±æ–½è¨­ç­‰ç·åˆç®¡ç†è¨ˆç”»", "kamijimachou_Public_facility_management_plan.pdf"),
    ("æ¸¯åŒº å…¬å…±æ–½è¨­ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆè¨ˆç”»", "minatoku_Public_facility_management_plan.pdf"),
]

DOC_TYPES = {
    "Structure_Base.pdf": "åŸºæº–",
    "kamijimachou_Public_facility_management_plan.pdf": "è¨ˆç”»",
    "minatoku_Public_facility_management_plan.pdf": "è¨ˆç”»",
}

# ã‚·ã‚¹ãƒ†ãƒ åˆ¶é™å€¤
MAX_SNIPPETS = 8
MAX_SNIPPET_CHARS = 1000
MAX_IMAGES_TOTAL = 12 # é¡•å¾®é¡ç”¨ã«å°‘ã—å¢—åŠ 

# é¡èªè¾æ›¸
QUERY_SYNONYMS = {
    "ã²ã³å‰²ã‚Œ": ["ã²ã³å‰²ã‚Œ", "ã‚¯ãƒ©ãƒƒã‚¯", "äº€è£‚", "ã²ã³"],
    "æµ®ã": ["æµ®ã", "ã†ã"],
    "å‰¥é›¢": ["å‰¥é›¢", "ã¯ãé›¢", "ã¯ãã‚Š"],
    "å«æ°´": ["å«æ°´", "æµ¸æ°´", "æ¼æ°´", "é›¨æ°´ä¾µå…¥", "é›¨æ¼ã‚Š"],
    "èµ¤å¤–ç·š": ["èµ¤å¤–ç·š", "IR", "ã‚µãƒ¼ãƒ¢", "ç†±ç”»åƒ", "ã‚µãƒ¼ãƒ¢ã‚°ãƒ©ãƒ•ã‚£"],
    "åŸºæº–": ["åŸºæº–", "åˆ¤å®š", "è©•ä¾¡", "é–¾å€¤", "è¨±å®¹"],
    "ã‚¿ã‚¤ãƒ«": ["ã‚¿ã‚¤ãƒ«", "ç£å™¨è³ªã‚¿ã‚¤ãƒ«", "ãƒ¢ã‚¶ã‚¤ã‚¯ã‚¿ã‚¤ãƒ«"],
    "ALC": ["ALC", "è»½é‡æ°—æ³¡ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ"],
    "ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ": ["ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ", "RC", "ä¸­æ€§åŒ–"],
    "é˜²æ°´": ["é˜²æ°´", "å¡—è†œ", "ã‚·ãƒ¼ãƒªãƒ³ã‚°", "ä¼¸ç¸®ç›®åœ°", "é˜²æ°´ã‚·ãƒ¼ãƒˆ", "ã‚·ãƒ¼ãƒˆé˜²æ°´"],
    "åŠ£åŒ–åº¦": ["åŠ£åŒ–åº¦", "ã‚°ãƒ¬ãƒ¼ãƒ‰", "åŒºåˆ†", "A", "B", "C", "D"],
}

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®šç¾©
MATERIAL_KEYWORDS: Dict[str, List[str]] = {
    "ã‚¿ã‚¤ãƒ«": ["ã‚¿ã‚¤ãƒ«", "ç£å™¨è³ªã‚¿ã‚¤ãƒ«", "ãƒ¢ã‚¶ã‚¤ã‚¯ã‚¿ã‚¤ãƒ«", "å¤–å£ã‚¿ã‚¤ãƒ«", "ç›®åœ°"],
    "å£": ["å£", "å¤–å£", "å†…å£", "ãƒ‘ãƒ©ãƒšãƒƒãƒˆ", "èº¯ä½“", "ãƒ¢ãƒ«ã‚¿ãƒ«", "ä»•ä¸Šã’"],
    "é˜²æ°´ã‚·ãƒ¼ãƒˆ": ["é˜²æ°´ã‚·ãƒ¼ãƒˆ", "ã‚·ãƒ¼ãƒˆé˜²æ°´", "å¡©ãƒ“ã‚·ãƒ¼ãƒˆ", "ã‚´ãƒ ã‚·ãƒ¼ãƒˆ", "å±‹ä¸Šé˜²æ°´", "ç«‹ä¸Šã‚Š", "ç«¯æœ«"],
    "ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ": ["ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ", "RC", "é‰„ç­‹ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ"],
    "ã‚·ãƒ¼ãƒªãƒ³ã‚°": ["ã‚·ãƒ¼ãƒªãƒ³ã‚°", "ã‚³ãƒ¼ã‚­ãƒ³ã‚°", "ç›®åœ°æ"],
}

DEFECT_KEYWORDS: Dict[str, List[str]] = {
    "ã²ã³å‰²ã‚Œ": ["ã²ã³å‰²ã‚Œ", "ã‚¯ãƒ©ãƒƒã‚¯", "äº€è£‚"],
    "æµ®ã": ["æµ®ã", "ã†ã"],
    "å‰¥é›¢": ["å‰¥é›¢", "ã¯ãé›¢", "ã¯ãã‚Š", "æ¬ æ", "è½ä¸‹"],
    "æ¼æ°´": ["æ¼æ°´", "é›¨æ¼ã‚Š", "æµ¸æ°´", "æ°´æ¼ã‚Œ", "é›¨æ°´ä¾µå…¥"],
    "ãµãã‚Œ": ["ãµãã‚Œ", "è†¨ã‚Œ", "ãƒ–ãƒªã‚¹ã‚¿ãƒ¼"],
    "ç ´æ–­": ["ç ´æ–­", "è£‚ã‘", "åˆ‡ã‚Œ", "ç ´ã‚Œ"],
    "ç«¯éƒ¨": ["ç«¯éƒ¨", "ç«¯æœ«", "ã‚ãã‚Œ", "å‰¥ãŒã‚Œ"],
    "ãƒ‰ãƒ¬ãƒ³": ["ãƒ‰ãƒ¬ãƒ³", "æ’æ°´å£", "ãƒ«ãƒ¼ãƒ•ãƒ‰ãƒ¬ãƒ³", "è©°ã¾ã‚Š"],
}

# è¨ºæ–­ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
TEMPLATES = {
    "å¤–å£ï¼ˆã‚¿ã‚¤ãƒ«ï¼‰": {
        "material_tags": ["ã‚¿ã‚¤ãƒ«", "å£", "ã‚·ãƒ¼ãƒªãƒ³ã‚°"],
        "checklist": [
            "å…¨æ™¯ï¼ˆå»ºç‰©å…¨ä½“ãƒ»æ–¹ä½ãŒåˆ†ã‹ã‚‹ï¼‰",
            "ä¸­æ™¯ï¼ˆç—‡çŠ¶ãŒå‡ºã¦ã„ã‚‹é¢ï¼‰",
            "è¿‘æ™¯ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«å…¥ã‚Šï¼šå®šè¦/ã‚³ã‚¤ãƒ³ç­‰ï¼‰",
            "é¡•å¾®é¡ï¼ˆç›®åœ°ã®æ¬ æãƒ»æµ®ãå£ï¼‰",
            "é–‹å£éƒ¨å‘¨ã‚Šï¼ˆã‚µãƒƒã‚·ãƒ»æ°´åˆ‡ã‚Šãƒ»å–ã‚Šåˆã„ï¼‰",
            "å¯èƒ½ãªã‚‰æ‰“è¨ºä½ç½®ï¼ˆæµ®ãç–‘ã„ï¼‰",
        ],
        "rag_preset": "base_focus",
    },
    "å£ï¼ˆä»•ä¸Šã’ãƒ»èº¯ä½“ï¼‰": {
        "material_tags": ["å£", "ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ", "ã‚·ãƒ¼ãƒªãƒ³ã‚°"],
        "checklist": [
            "å…¨æ™¯ï¼ˆå»ºç‰©å…¨ä½“ãƒ»æ–¹ä½ï¼‰",
            "ä¸­æ™¯ï¼ˆç—‡çŠ¶ãŒå‡ºã¦ã„ã‚‹é¢ï¼‰",
            "è¿‘æ™¯ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«å…¥ã‚Šï¼‰",
            "é¡•å¾®é¡ï¼ˆã²ã³å‰²ã‚Œå†…éƒ¨ãƒ»ã‚¨ãƒ•ãƒ­ï¼‰",
            "é›¨æ›ã‹ã‚Šãƒ©ã‚¤ãƒ³ï¼ˆæ±šã‚Œç­‹ãƒ»ç™½è¯ï¼‰",
            "é–‹å£éƒ¨ãƒ»å–ã‚Šåˆã„ï¼ˆã‚¯ãƒ©ãƒƒã‚¯èµ·ç‚¹ã«ãªã‚Šã‚„ã™ã„ï¼‰",
        ],
        "rag_preset": "base_focus",
    },
    "å±‹ä¸Šï¼ˆé˜²æ°´ã‚·ãƒ¼ãƒˆï¼‰": {
        "material_tags": ["é˜²æ°´ã‚·ãƒ¼ãƒˆ", "é˜²æ°´", "ãƒ‰ãƒ¬ãƒ³", "ç«¯éƒ¨"],
        "checklist": [
            "å…¨æ™¯ï¼ˆå±‹ä¸Šå…¨ä½“ï¼šå‹¾é…ãƒ»æ’æ°´ç³»ãŒåˆ†ã‹ã‚‹ï¼‰",
            "ã‚·ãƒ¼ãƒˆç¶™ãç›®ï¼ˆã‚¸ãƒ§ã‚¤ãƒ³ãƒˆãƒ»æº¶ç€éƒ¨ï¼‰",
            "ç«‹ä¸Šã‚Šï¼ˆãƒ‘ãƒ©ãƒšãƒƒãƒˆå–ã‚Šåˆã„ï¼‰",
            "ç«¯æœ«æŠ¼ã•ãˆï¼ˆé‡‘ç‰©ãƒ»ã‚·ãƒ¼ãƒ«ï¼‰",
            "é¡•å¾®é¡ï¼ˆã‚·ãƒ¼ãƒˆè¡¨é¢ã®ç´«å¤–ç·šåŠ£åŒ–/äº€è£‚ï¼‰",
            "ãµãã‚Œ/æµ®ã/ç ´ã‚Œã®è¿‘æ™¯ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«å…¥ã‚Šï¼‰",
        ],
        "rag_preset": "base_and_plan",
    },
}

SYMPTOMS = [
    "ã²ã³å‰²ã‚Œ",
    "æµ®ã",
    "å‰¥é›¢ãƒ»æ¬ æãƒ»è½ä¸‹æ‡¸å¿µ",
    "æ¼æ°´ãƒ»é›¨æ¼ã‚Š",
    "ãµãã‚Œï¼ˆãƒ–ãƒªã‚¹ã‚¿ãƒ¼ï¼‰",
    "ç ´æ–­ãƒ»è£‚ã‘ãƒ»ç ´ã‚Œ",
    "ç«¯éƒ¨ã‚ãã‚Œãƒ»ç«¯æœ«ä¸è‰¯",
    "ã‚·ãƒ¼ãƒªãƒ³ã‚°åŠ£åŒ–",
    "ãƒ‰ãƒ¬ãƒ³è©°ã¾ã‚Šç–‘ã„",
    "åŸå› ä¸æ˜ï¼ˆç·åˆï¼‰",
]


# ===========================================================
# 2. Helper Functions (Text, Image, Utils)
# ===========================================================

def normalize_text(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–ï¼ˆNFKC, æ”¹è¡Œå‰Šé™¤, ç©ºç™½çŸ­ç¸®ï¼‰"""
    text = unicodedata.normalize("NFKC", text)
    text = text.replace("\r", " ").replace("\n", " ")
    text = re.sub(r"\s+", " ", text).strip()
    return text


def tokenize(s: str) -> List[str]:
    """ç°¡æ˜“ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼"""
    s = s.lower()
    s = re.sub(r"[^\wä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³ï¼…â„ƒï¼\.]", " ", s)
    s = s.replace("ï¼", ".")
    s = re.sub(r"\s+", " ", s).strip()
    return s.split()


def query_expand_tokens(q: str) -> List[str]:
    """åŒç¾©èªå±•é–‹ã«ã‚ˆã‚‹ã‚¯ã‚¨ãƒªæ‹¡å¼µ"""
    tokens = set(tokenize(q))
    for key, syns in QUERY_SYNONYMS.items():
        if key in q or any(s in q for s in syns):
            for s2 in syns:
                tokens.update(tokenize(s2))
    return list(tokens)


def pil_stats(image: Image.Image, target_w: int = 256) -> Dict[str, float]:
    """ç”»åƒã‹ã‚‰ç°¡æ˜“çš„ãªçµ±è¨ˆé‡ã‚’æŠ½å‡º"""
    if image.mode != "RGB":
        image = image.convert("RGB")
    
    # ãƒªã‚µã‚¤ã‚ºã—ã¦è¨ˆç®—ã‚³ã‚¹ãƒˆå‰Šæ¸›
    w = target_w if image.width > target_w else image.width
    ratio = w / image.width if image.width else 1.0
    image = image.resize((w, max(1, int(image.height * ratio))))
    
    gray = image.convert("L")
    pixels = list(gray.getdata())
    
    mean_l = statistics.fmean(pixels) if pixels else 0.0
    stdev_l = statistics.pstdev(pixels) if pixels else 0.0
    
    edges = gray.filter(ImageFilter.FIND_EDGES)
    epx = list(edges.getdata())
    strong = sum(1 for v in epx if v > 60)
    edge_ratio = strong / len(epx) if epx else 0.0
    
    hsv = image.convert("HSV")
    sat_vals = [p[1] for p in list(hsv.getdata())]
    sat_mean = statistics.fmean(sat_vals) if sat_vals else 0.0
    
    return {
        "mean_l": round(mean_l, 2),
        "stdev_l": round(stdev_l, 2),
        "edge_ratio": round(edge_ratio, 4),
        "sat_mean": round(sat_mean, 2),
    }


def analyze_visual(image: Image.Image, target_w: int = 256) -> Dict[str, Any]:
    """å¯è¦–ç”»åƒã®ç°¡æ˜“è§£æ"""
    s = pil_stats(image, target_w=target_w)
    crack_hint = s["edge_ratio"] > 0.11
    stain_hint = s["sat_mean"] < 70 and s["mean_l"] < 110
    
    level = "low"
    if crack_hint and stain_hint:
        level = "mid"
    if s["edge_ratio"] > 0.16:
        level = "mid"
    if s["edge_ratio"] > 0.22:
        level = "high"
        
    return {
        "metrics": s,
        "crack_hint": crack_hint,
        "stain_hint": stain_hint,
        "screening_level": level,
        "note": "ç”»åƒãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“å‚¾å‘ã€‚å¯¸æ³•ãƒ»å¹…ãªã©ã¯ç”»åƒã ã‘ã§ã¯ç¢ºå®šã§ãã¾ã›ã‚“ã€‚"
    }


def analyze_ir(image: Image.Image, meta: Dict[str, str], target_w: int = 256) -> Dict[str, Any]:
    """IRï¼ˆèµ¤å¤–ç·šï¼‰ç”»åƒã®ç°¡æ˜“è§£æ"""
    gray = image.convert("L")
    w = target_w if gray.width > target_w else gray.width
    gray = gray.resize((w, max(1, int(gray.height * (w / (gray.width or 1))))))
    
    vals = list(gray.getdata())
    if not vals:
        return {"has_ir": True, "delta_rel": 0.0, "pattern": "unknown", "note": "ç”»åƒãƒ‡ãƒ¼ã‚¿ç„¡ã—"}
        
    vmin, vmax = min(vals), max(vals)
    delta = vmax - vmin
    stdev = statistics.pstdev(vals)
    
    pattern = "uniform"
    if stdev > 20 and delta > 40:
        pattern = "hot/cold spots"
    if stdev > 30 and delta > 60:
        pattern = "strong hotspots"
        
    return {
        "has_ir": True,
        "delta_rel": round(delta / 255.0, 3),
        "stdev": round(stdev, 2),
        "pattern": pattern,
        "meta": meta,
        "note": "JPEGã®è¼åº¦å·®ã‹ã‚‰è¦‹ãŸç›¸å¯¾çš„ãªãƒ ãƒ©è©•ä¾¡ã€‚æ”¾å°„ç‡/åå°„æ¸©åº¦ç­‰ã®è£œæ­£ç„¡ã—ã€‚"
    }


def image_to_inline_part(image: Image.Image, max_width: int = 1400) -> Dict:
    """Gemini APIç”¨ã®ç”»åƒãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ä½œæˆ"""
    if image.mode != "RGB":
        image = image.convert("RGB")
    if image.width > max_width:
        r = max_width / float(image.width)
        image = image.resize((max_width, int(image.height * r)))
        
    buf = io.BytesIO()
    image.save(buf, format="JPEG", quality=90, optimize=True)
    b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
    return {"inline_data": {"mime_type": "image/jpeg", "data": b64}}


# ===========================================================
# 3. RAG Core Logic (PDF Processing & Search)
# ===========================================================

class BM25Index:
    def __init__(self, k1: float = 1.6, b: float = 0.75):
        self.k1, self.b = k1, b
        self.N = 0
        self.avgdl = 0.0
        self.df: Dict[str, int] = {}
        self.doc_len: List[int] = []
        self.postings: Dict[str, List[Tuple[int, int]]] = {}
        self.docs: List[Dict[str, Any]] = []

    def _tf(self, tokens: List[str]) -> Dict[str, int]:
        tf: Dict[str, int] = {}
        for t in tokens:
            tf[t] = tf.get(t, 0) + 1
        return tf

    def build(self, docs: List[Dict[str, Any]]):
        self.docs = docs
        self.N = len(docs)
        lengths = []
        for doc_id, d in enumerate(docs):
            tokens = tokenize(d["text"])
            d["_tokens"] = tokens
            tf = self._tf(tokens)
            lengths.append(len(tokens))
            for term, c in tf.items():
                self.df[term] = self.df.get(term, 0) + 1
                self.postings.setdefault(term, []).append((doc_id, c))
        self.doc_len = lengths
        self.avgdl = (sum(lengths) / self.N) if self.N else 0.0

    def idf(self, term: str) -> float:
        df = self.df.get(term, 0)
        return math.log((self.N - df + 0.5) / (df + 0.5) + 1.0)

    def score_doc(self, q_tokens: List[str], doc_id: int) -> float:
        score = 0.0
        dl = self.doc_len[doc_id] if doc_id < len(self.doc_len) else 0
        if dl == 0:
            return 0.0
        for term in set(q_tokens):
            plist = self.postings.get(term)
            if not plist:
                continue
            tf = 0
            for did, c in plist:
                if did == doc_id:
                    tf = c
                    break
            if tf == 0:
                continue
            idf = self.idf(term)
            denom = tf + self.k1 * (1 - self.b + self.b * (dl / (self.avgdl or 1.0)))
            score += idf * (tf * (self.k1 + 1)) / (denom or 1.0)
        return score


def extract_chunks_from_pdf(pdf_path: str, title: str, max_chars: int = 900, overlap: int = 120) -> List[Dict[str, Any]]:
    if not os.path.exists(pdf_path):
        return []
    chunks = []
    base = os.path.basename(pdf_path)
    doc_type = DOC_TYPES.get(base, "ãã®ä»–")
    try:
        with open(pdf_path, "rb") as f:
            reader = PyPDF2.PdfReader(f)
            for i, page in enumerate(reader.pages, start=1):
                t = page.extract_text() or ""
                page_text = normalize_text(t)
                if not page_text:
                    continue
                pos = 0
                while pos < len(page_text):
                    end = min(pos + max_chars, len(page_text))
                    ch = page_text[pos:end].strip()
                    if ch:
                        chunks.append({
                            "doc": title,
                            "path": pdf_path,
                            "text": ch,
                            "page_start": i,
                            "page_end": i,
                            "doc_type": doc_type,
                        })
                    pos = end - overlap if (end - overlap) > pos else end
    except Exception as e:
        chunks.append({
            "doc": title, "path": pdf_path,
            "text": f"[PDFèª­è¾¼ã‚¨ãƒ©ãƒ¼:{pdf_path}:{e}]",
            "page_start": None, "page_end": None,
            "doc_type": doc_type,
        })
    return chunks


@st.cache_resource(show_spinner=False)
def build_rag() -> Dict[str, Any]:
    all_chunks = []
    for title, path in PDF_SOURCES:
        all_chunks.extend(extract_chunks_from_pdf(path, title))

    for d in all_chunks:
        txt = d["text"]
        d["_has_numbers"] = bool(re.search(r"\b\d+(\.\d+)?\s*(mm|ãœ|ï¼…|%|â„ƒ)\b", txt))
        d["_has_ir"] = any(k in txt for k in ["èµ¤å¤–ç·š", "ã‚µãƒ¼ãƒ¢", "IR", "ç†±ç”»åƒ", "æ”¾å°„ç‡", "åå°„ç‡", "åå°„æ¸©åº¦"])

        mats = set()
        defs = set()
        for mk, words in MATERIAL_KEYWORDS.items():
            if any(w in txt for w in words):
                mats.add(mk)
        for dk, words in DEFECT_KEYWORDS.items():
            if any(w in txt for w in words):
                defs.add(dk)
        d["_materials"] = mats
        d["_defects"] = defs

    bm25 = BM25Index()
    if all_chunks:
        bm25.build(all_chunks)
    return {"index": bm25, "docs": all_chunks}


def rag_search(query: str, have_ir: bool, k: int, weights: Dict[str, float]) -> List[Dict[str, Any]]:
    data = build_rag()
    bm25: BM25Index = data["index"]
    docs = data["docs"]
    if not docs:
        return []

    q_tokens = query_expand_tokens(query)
    
    # ã‚¯ã‚¨ãƒªè§£æ
    q_mats = {mk for mk, words in MATERIAL_KEYWORDS.items() if any(w in query for w in words)}
    q_defs = {dk for dk, words in DEFECT_KEYWORDS.items() if any(w in query for w in words)}
    
    want_threshold = any(w in query for w in ["åŸºæº–", "é–¾å€¤", "å¹…", "mm", "ãœ", "ï¼…", "%", "â„ƒ", "æ¸©åº¦", "åˆ¤å®š", "è¨±å®¹"])
    want_ir_q = any(w in query for w in ["èµ¤å¤–ç·š", "IR", "ã‚µãƒ¼ãƒ¢", "ç†±ç”»åƒ", "ã‚µãƒ¼ãƒ¢ã‚°ãƒ©ãƒ•ã‚£"])
    
    boost_muni = "æ¸¯åŒº" if "æ¸¯åŒº" in query else ("ä¸Šå³¶ç”º" if ("ä¸Šå³¶ç”º" in query or "ä¸Šå¶‹ç”º" in query) else None)

    scored = []
    for doc_id, d in enumerate(docs):
        base = bm25.score_doc(q_tokens, doc_id)
        if base <= 0:
            continue

        if want_threshold and d.get("_has_numbers"):
            base *= weights["number_boost"]
        if (have_ir or want_ir_q) and d.get("_has_ir"):
            base *= weights["ir_boost"]

        doc_type = d.get("doc_type", "ãã®ä»–")
        if doc_type == "åŸºæº–":
            base *= weights["base_weight"]
        elif doc_type == "è¨ˆç”»":
            base *= weights["plan_weight"]
        else:
            base *= weights["other_weight"]

        mats = d.get("_materials", set())
        defs = d.get("_defects", set())
        mat_match = bool(q_mats & mats)
        def_match = bool(q_defs & defs)

        if mat_match:
            base *= weights["material_boost"]
        if def_match:
            base *= weights["defect_boost"]
        if mat_match and def_match:
            base *= weights["mat_def_synergy"]

        if boost_muni and boost_muni in d.get("doc", ""):
            base *= weights["muni_boost"]

        scored.append((base, doc_id))

    scored.sort(key=lambda x: x[0], reverse=True)
    top_docs = [docs[i] for (score, i) in scored[:k]]

    for t in top_docs:
        if len(t["text"]) > MAX_SNIPPET_CHARS:
            t["text"] = t["text"][:MAX_SNIPPET_CHARS] + "â€¦"
    return top_docs


# ===========================================================
# 4. Prompt & Report Logic
# ===========================================================

def build_auto_question(template_name: str, symptoms: List[str], free_text: str, want_threshold: bool, want_plan: bool) -> str:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰RAGæ¤œç´¢ã«æœ€é©ãªè³ªå•æ–‡ã‚’ç”Ÿæˆ"""
    base = f"å¯¾è±¡: {template_name}ã€‚ç—‡çŠ¶: {', '.join(symptoms) if symptoms else 'æœªé¸æŠ'}ã€‚"
    add = free_text.strip()
    asks = [
        "è¦³å¯Ÿæ‰€è¦‹ã‹ã‚‰æƒ³å®šã•ã‚Œã‚‹åŸå› å€™è£œï¼ˆå–ã‚Šåˆã„ã€ç›®åœ°ã€ç«¯æœ«ã€æ’æ°´ã€ä¸‹åœ°ç­‰ï¼‰ã‚’æ•´ç†ã—ã¦ã»ã—ã„",
        "è½ä¸‹/å‰¥é›¢/æ¼æ°´æ‹¡å¤§ãªã©ã®ãƒªã‚¹ã‚¯ã¨ã€ä¸€æ¬¡å¯¾å¿œï¼ˆç«‹å…¥åˆ¶é™ãƒ»ä»®è¨­é˜²è­·ãƒ»å¿œæ€¥æ­¢æ°´ç­‰ï¼‰ã®å„ªå…ˆåº¦ã‚’ç¤ºã—ã¦ã»ã—ã„",
        "æ’ä¹…å¯¾ç­–ã®é¸æŠè‚¢ï¼ˆè£œä¿®ãƒ»éƒ¨åˆ†æ”¹ä¿®ãƒ»å…¨é¢æ”¹ä¿®ï¼‰ã‚’ã€å„ªå…ˆé †ä½ã¤ãã§ææ¡ˆã—ã¦ã»ã—ã„",
        "è¿½åŠ èª¿æŸ»ï¼ˆæ‰“è¨ºã€æ•£æ°´ã€å«æ°´ç‡ã€ä»˜ç€åŠ›ã€ç«¯æœ«é–‹å£ç¢ºèªãªã©ï¼‰ã®ç›®çš„ã¨æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã»ã—ã„"
    ]

    if want_threshold:
        asks.insert(0, "åŸºæº–ï¼ˆè¨±å®¹ãƒ»åˆ¤å®šãƒ»æ³¨æ„å–šèµ·ï¼‰ã«è©²å½“ã™ã‚‹è¨˜è¿°ãŒã‚ã‚Œã°æ ¹æ‹ ä»˜ãã§ç¤ºã—ã¦ã»ã—ã„ï¼ˆæ•°å€¤ã¯å‡ºå…¸å¿…é ˆï¼‰")
    if want_plan:
        asks.insert(1, "ç¶­æŒç®¡ç†è¨ˆç”»ãƒ»æ›´æ–°å„ªå…ˆåº¦ãƒ»LCCè¦³ç‚¹ã§ã€ç·Šæ€¥åº¦/é‡è¦åº¦ã®æ•´ç†ã‚‚ã—ã¦ã»ã—ã„")

    tags = []
    # ã‚¿ã‚°ä»˜ã‘ãƒ­ã‚¸ãƒƒã‚¯
    for t in TEMPLATES.get(template_name, {}).get("material_tags", []):
        tags.append(t)
    for s in symptoms:
        if "å‰¥é›¢" in s or "è½ä¸‹" in s: tags.append("å‰¥é›¢")
        if "æ¼æ°´" in s or "é›¨æ¼ã‚Š" in s: tags.append("æ¼æ°´")
        if "ã²ã³" in s: tags.append("ã²ã³å‰²ã‚Œ")
        if "ãµãã‚Œ" in s: tags.append("ãµãã‚Œ")
        if "ç ´æ–­" in s or "ç ´ã‚Œ" in s: tags.append("ç ´æ–­")
        if "ç«¯éƒ¨" in s: tags.append("ç«¯éƒ¨")
        if "ãƒ‰ãƒ¬ãƒ³" in s: tags.append("ãƒ‰ãƒ¬ãƒ³")
        if "ã‚·ãƒ¼ãƒªãƒ³ã‚°" in s: tags.append("ã‚·ãƒ¼ãƒªãƒ³ã‚°")

    tag_str = " / ".join(sorted(set(tags))) if tags else ""

    q = f"""{base}
è£œè¶³: {add if add else 'ï¼ˆãªã—ï¼‰'}

ä¾é ¼:
- {chr(10)+'- '.join(asks)}

æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆRAGè£œåŠ©ï¼‰: {tag_str}
""".strip()
    return normalize_text(q)


def call_gemini(api_key: str, prompt_text: str, image_parts: List[Dict], max_retries: int = 3) -> Dict:
    url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + api_key
    headers = {"Content-Type": "application/json"}
    parts = [{"text": prompt_text}] + image_parts
    payload = {"contents": [{"parts": parts}]}

    last_err = None
    for attempt in range(1, max_retries + 1):
        try:
            resp = requests.post(url, headers=headers, json=payload, timeout=120)
            resp.raise_for_status()
            return resp.json()
        except requests.HTTPError as e:
            status = e.response.status_code if e.response is not None else None
            if status in (503, 429) and attempt < max_retries:
                wait = min(12, 2 ** attempt + 1)
                st.toast(f"Geminiæ··é›‘ä¸­ï¼ˆ{status}ï¼‰ã€‚{wait}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™...", icon="âš ï¸")
                time.sleep(wait)
                last_err = e
                continue
            last_err = e
            break
        except Exception as e:
            last_err = e
            break
            
    if last_err:
        raise last_err
    raise RuntimeError("Gemini API call failed.")


def build_master_prompt(user_q, rag_snippets, priors, vis_list, ir_list, micro_list, rule_grade, rule_life, ir_meta_note):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆGeminié€ä¿¡å†…å®¹ï¼‰: é¡•å¾®é¡å¯¾å¿œ"""
    # RAGæƒ…å ±ã®æ•´å½¢
    labeled_snips = []
    counter = 1
    blocks = []
    
    def format_snips(snips, label):
        nonlocal counter
        lines = []
        for d in snips:
            rid = f"R{counter}"
            dd = dict(d)
            dd["_rag_id"] = rid
            labeled_snips.append(dd)
            pg = f" p.{dd['page_start']}" if dd.get("page_start") else ""
            lines.append(f"[{rid} {label} {dd.get('doc','')}{pg}] {dd.get('text','')}")
            counter += 1
        return "\n".join(lines)

    base_snips = [d for d in rag_snippets if d.get("doc_type") == "åŸºæº–"]
    plan_snips = [d for d in rag_snippets if d.get("doc_type") == "è¨ˆç”»"]
    other_snips = [d for d in rag_snippets if d.get("doc_type") not in ("åŸºæº–", "è¨ˆç”»")]

    if base_snips: blocks.append("# RAGåŸºæº–å€™è£œ:\n" + format_snips(base_snips, "åŸºæº–"))
    if plan_snips: blocks.append("# RAGè¨ˆç”»ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ:\n" + format_snips(plan_snips, "è¨ˆç”»"))
    if other_snips: blocks.append("# RAGãã®ä»–å‚è€ƒ:\n" + format_snips(other_snips, "å‚è€ƒ"))
    
    rag_text = "\n\n".join(blocks) if blocks else "ï¼ˆè©²å½“æŠœç²‹ãªã—ï¼‰"

    # ç”»åƒæƒ…å ±ã®æ•´å½¢
    vis_block = "\n".join([f"- edge={v['metrics']['edge_ratio']} crack={v['crack_hint']} level={v['screening_level']}" for v in vis_list]) or "ï¼ˆå¯è¦–ç”»åƒãªã—ï¼‰"
    ir_block = "\n".join([f"- delta={i['delta_rel']} pattern={i['pattern']}" for i in ir_list]) or "ï¼ˆIRç”»åƒãªã—ï¼‰"
    
    # é¡•å¾®é¡æƒ…å ±ã®æ•´å½¢ (New)
    micro_block = "ï¼ˆé¡•å¾®é¡ç”»åƒãªã—ï¼‰"
    if micro_list:
        micro_block = "â€»1000å€é¡•å¾®é¡ç”»åƒãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚å¾®ç´°ãªäº€è£‚ã€çµæ™¶åŒ–ã€è…é£Ÿãƒ‘ã‚¿ãƒ¼ãƒ³ã€è¡¨é¢ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’ææ–™ç§‘å­¦çš„ã«åˆ†æã—ã¦ãã ã•ã„ã€‚"

    today = date.today().strftime("%Yå¹´%mæœˆ%dæ—¥")

    prompt = f"""
ã‚ãªãŸã¯éç ´å£Šæ¤œæŸ»ãƒ»å»ºç¯‰ãƒ»ææ–™å­¦ã®ä¸Šç´šè¨ºæ–­å£«ã€‚å›½åœŸäº¤é€šçœï¼ˆMLITï¼‰é–¢é€£æ–‡æ›¸ã®é©åˆæ€§ã‚’é‡è¦–ã—ã€ä¸ãˆãŸRAGæŠœç²‹ã®ç¯„å›²å†…ã§**è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ**ã‚’ä½œæˆã™ã‚‹ã€‚
ç¦æ­¢ï¼šæ¨æ¸¬ã§ã®æ•°å€¤åŒ–ï¼ˆé–¾å€¤ãƒ»ã²ã³å¹…ç­‰ï¼‰ï¼æœªå‡ºå…¸ã®æ–­å®šã€‚æ ¹æ‹ ãŒç„¡ã„å ´åˆã¯ã€Œæœªæ²è¼‰ï¼æœªç¢ºå®šã€ã¨æ˜ç¤ºã€‚

# å…¥åŠ›
- ä½œæˆæ—¥: {today}
- ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {user_q}

- RAGæŠœç²‹ï¼ˆIDä»˜ãã€‚åŸå‰‡ã“ã‚Œä»¥å¤–ã¯æ ¹æ‹ ã«ã—ãªã„ï¼‰:
{rag_text}

- ä¸€èˆ¬åŸå‰‡:
{priors}

- å¯è¦–ç”»åƒæ‰€è¦‹:
{vis_block}

- IRç”»åƒæ‰€è¦‹ï¼ˆç›¸å¯¾è©•ä¾¡ï¼‰:
{ir_block}
{ir_meta_note}

- é¡•å¾®é¡ç”»åƒæ‰€è¦‹ï¼ˆè©³ç´°è§£æç”¨ï¼‰:
{micro_block}

- ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æš«å®š:
  * æš«å®šã‚°ãƒ¬ãƒ¼ãƒ‰: {rule_grade}
  * å‚è€ƒå¯¿å‘½: {rule_life}

# å‡ºåŠ›ä»•æ§˜ï¼ˆMarkdownï¼‰
- å…ˆé ­ï¼šç·åˆè©•ä¾¡ï¼ˆA/B/C/Dã€ä¸»å› 1â€“2è¡Œã€ç¢ºåº¦ã‚‚ä¸€è¨€ï¼‰
- åŸºæº–ãƒ»è¨ˆç”»ã¨ã®æ•´åˆï¼šRAG IDï¼ˆä¾‹ï¼šï¼»æ ¹æ‹ : R1,R3ï¼½ï¼‰ã‚’å¿…ãšä»˜ä¸ã€‚ãªã‘ã‚Œã°ï¼»æ ¹æ‹ : æœªæ²è¼‰ï¼ˆä¸€èˆ¬åŸå‰‡ãƒ™ãƒ¼ã‚¹ï¼‰ï¼½
- é¡•å¾®é¡åˆ†æï¼ˆã‚ã‚‹å ´åˆï¼‰ï¼šãƒŸã‚¯ãƒ­è¦–ç‚¹ã§ã®åŠ£åŒ–ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼ˆã‚¨ãƒ•ãƒ­ã€åˆæœŸè…é£Ÿã€ç´«å¤–ç·šåŠ£åŒ–ç­‰ï¼‰ã¸ã®è¨€åŠã€‚
- ãƒªã‚¹ã‚¯ï¼ˆè½ä¸‹ãƒ»æ¼æ°´æ‹¡å¤§ç­‰ï¼‰â†’ å¿œæ€¥å¯¾å¿œ â†’ æ’ä¹…å¯¾ç­–ï¼ˆé¸æŠè‚¢ï¼‰â†’ è¿½åŠ èª¿æŸ»ï¼ˆç›®çš„/æ–¹æ³•ï¼‰ã‚’å¿…ãšå«ã‚ã‚‹
- IRã¯ç›¸å¯¾æŒ‡æ¨™ã§ã‚ã‚Šã€æ—¥å°„/é›¨ç›´å¾Œç­‰ã®æ¡ä»¶å½±éŸ¿ã‚’å¿…ãšæ›¸ã
""".strip()
    return normalize_text(prompt), labeled_snips


def rule_based_grade(vis_list, ir_list):
    """ç”»åƒç‰¹å¾´é‡ã®ã¿ã‹ã‚‰ã®ç°¡æ˜“åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯"""
    score = 0.0
    reasons = []
    
    if vis_list:
        er_max = max(v["metrics"]["edge_ratio"] for v in vis_list)
        if er_max > 0.22: score += 3; reasons.append(f"å¼·ã„ã‚¨ãƒƒã‚¸å¯†åº¦ï¼ˆ{er_max:.3f}ï¼‰")
        elif er_max > 0.16: score += 2; reasons.append(f"é«˜ã‚ã®ã‚¨ãƒƒã‚¸å¯†åº¦ï¼ˆ{er_max:.3f}ï¼‰")
        elif er_max > 0.11: score += 1; reasons.append(f"ã‚„ã‚„é«˜ã„ã‚¨ãƒƒã‚¸å¯†åº¦ï¼ˆ{er_max:.3f}ï¼‰")
        
        if any(v.get("stain_hint") for v in vis_list):
            score += 1; reasons.append("ä½å½©åº¦ãƒ»æš—éƒ¨å¤šã‚ã§æ±šæŸ“å‚¾å‘")
            
    if ir_list:
        dr_max = max(i["delta_rel"] for i in ir_list)
        if dr_max > 0.5: score += 3; reasons.append(f"IRè¼åº¦å·®ãŒå¤§ï¼ˆ{dr_max:.2f}ï¼‰")
        elif dr_max > 0.3: score += 2; reasons.append(f"IRè¼åº¦å·®ãŒä¸­ï¼ˆ{dr_max:.2f}ï¼‰")
        elif dr_max > 0.15: score += 1; reasons.append(f"IRè¼åº¦å·®ãŒã‚„ã‚„å¤§ï¼ˆ{dr_max:.2f}ï¼‰")
        
        if any(i.get("pattern") == "strong hotspots" for i in ir_list):
            score += 1; reasons.append("å¼·ã„ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆ")

    if score <= 1: g = "A"
    elif score <= 3: g = "B"
    elif score <= 5: g = "C"
    else: g = "D"
    
    return g, "ãƒ»".join(reasons) if reasons else "é¡•è‘—ãªç•°å¸¸ãªã—ï¼ˆç”»åƒãƒ™ãƒ¼ã‚¹ï¼‰"


# ===========================================================
# 5. UI Components & CSS
# ===========================================================

def inject_custom_css():
    st.markdown(
        """
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;500;700;900&display=swap');
        html, body, [class*="css"] {
            font-family: 'Noto Sans JP', sans-serif;
            color: #333;
        }
        .hero-container {
            background: linear-gradient(135deg, #2563EB 0%, #06B6D4 100%);
            padding: 2rem;
            border-radius: 16px;
            color: white;
            box-shadow: 0 4px 15px rgba(0, 184, 212, 0.3);
            margin-bottom: 2rem;
        }
        .hero-title {
            font-size: 1.8rem;
            font-weight: 900;
            margin-bottom: 0.5rem;
        }
        .hero-subtitle {
            font-size: 0.9rem;
            opacity: 0.9;
        }
        .app-card {
            background: white;
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            border: 1px solid #E5E7EB;
            box-shadow: 0 2px 5px rgba(0,0,0,0.03);
        }
        .card-header {
            font-size: 1.1rem;
            font-weight: 700;
            margin-bottom: 1rem;
            border-bottom: 2px solid #F3F4F6;
            padding-bottom: 0.5rem;
            color: #1F2937;
        }
        .stTabs [data-baseweb="tab-list"] {
            gap: 8px;
        }
        .stTabs [data-baseweb="tab"] {
            height: 50px;
            border-radius: 8px;
            background-color: #F9FAFB;
            border: 1px solid #E5E7EB;
            padding: 0 20px;
            font-weight: 600;
        }
        .stTabs [aria-selected="true"] {
            background-color: #2563EB;
            color: white !important;
            border: none;
        }
        .stButton > button {
            border-radius: 8px !important;
            font-weight: 600 !important;
            padding: 0.5rem 1rem !important;
        }
        div[data-testid="stToast"] {
            border-radius: 8px !important;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

def render_header():
    st.markdown(
        f"""
        <div class="hero-container">
            <div class="hero-title">ğŸ—ï¸ {APP_TITLE}</div>
            <div class="hero-subtitle">
                AI Building Diagnosis / Gemini 2.5 Flash / RAG Fail-Safe System<br>
                å¯è¦–ãƒ»IRãƒ»<strong>1000å€é¡•å¾®é¡</strong>ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è§£æã«å¯¾å¿œ
            </div>
        </div>
        """,
        unsafe_allow_html=True
    )

def ensure_session_state():
    if "vis_gallery" not in st.session_state: st.session_state["vis_gallery"] = []
    if "ir_gallery" not in st.session_state: st.session_state["ir_gallery"] = []
    if "micro_gallery" not in st.session_state: st.session_state["micro_gallery"] = [] # New

def add_image_to_gallery(img: Image.Image, type_key: str):
    """ã‚®ãƒ£ãƒ©ãƒªãƒ¼ã¸ç”»åƒè¿½åŠ ï¼ˆãƒªã‚µã‚¤ã‚ºãƒ»ä¸Šé™ç®¡ç†å«ã‚€ï¼‰"""
    if img is None: return
    if img.mode != "RGB": img = img.convert("RGB")
    
    # ãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚ãƒªã‚µã‚¤ã‚ºã—ã¦ä¿æŒ
    if img.width > 1200:
        r = 1200 / float(img.width)
        img = img.resize((1200, int(img.height * r)))
        
    st.session_state[type_key].append(img)
    st.toast("ç”»åƒã‚’è¿½åŠ ã—ã¾ã—ãŸ", icon="ğŸ“¸")
    
    # ä¸Šé™ç®¡ç†ï¼ˆFIFOï¼‰
    all_len = sum(len(st.session_state[k]) for k in ["vis_gallery", "ir_gallery", "micro_gallery"])
    if all_len > MAX_IMAGES_TOTAL:
        # å¤ã„ã‚‚ã®ã‹ã‚‰æ¶ˆã™å„ªå…ˆåº¦: IR > Vis > Micro
        if st.session_state["ir_gallery"]: st.session_state["ir_gallery"].pop(0)
        elif st.session_state["vis_gallery"]: st.session_state["vis_gallery"].pop(0)
        elif st.session_state["micro_gallery"]: st.session_state["micro_gallery"].pop(0)

# ===========================================================
# 6. Main App
# ===========================================================

def main():
    st.set_page_config(page_title=APP_TITLE, layout="wide", initial_sidebar_state="expanded")
    inject_custom_css()
    ensure_session_state()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆè¨­å®šãƒ»ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼‰
    with st.sidebar:
        st.markdown("### âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
        fast_mode = st.toggle("âš¡ é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰", value=True, help="RAGæ¤œç´¢æ•°ã¨ç”»åƒã‚µã‚¤ã‚ºã‚’ç¸®å°ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å„ªå…ˆã—ã¾ã™ã€‚")
        debug_mode = st.toggle("ğŸ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰", value=False)
        
        st.divider()
        st.markdown("### ğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
        
        # API Key check
        has_api_key = False
        try:
            if st.secrets["gemini"]["API_KEY"]:
                has_api_key = True
        except:
            pass
            
        if has_api_key:
            st.success("API Key: OK")
        else:
            st.error("API Key: æœªè¨­å®š")
            st.caption(".streamlit/secrets.toml ã‚’ç¢ºèªã—ã¦ãã ã•ã„")

        # PDF check
        missing = [p for _, p in PDF_SOURCES if not os.path.exists(p)]
        if missing:
            st.warning(f"PDFä¸è¶³: {len(missing)}ä»¶")
        else:
            st.success("RAG Data: OK")
            
        st.divider()
        st.caption(f"Ver {APP_VERSION}")

    render_header()

    # ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ–
    tab1, tab2, tab3, tab4 = st.tabs([
        "â‘  è¨ºæ–­ãƒ†ãƒ³ãƒ—ãƒ¬", 
        "â‘¡ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
        "â‘¢ ä½ç½®æƒ…å ±", 
        "â‘£ è¨ºæ–­å®Ÿè¡Œ"
    ])

    # --- Tab 1: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨è³ªå• ---
    with tab1:
        st.markdown('<div class="app-card">', unsafe_allow_html=True)
        st.markdown('<div class="card-header">ğŸ“‹ è¨ºæ–­æ¡ä»¶ã®è¨­å®š</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 1])
        with col1:
            template_name = st.selectbox("å¯¾è±¡éƒ¨ä½ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼‰", list(TEMPLATES.keys()))
            want_threshold = st.checkbox("åŸºæº–å€¤ï¼ˆåˆ¤å®šåŸºæº–ï¼‰ã‚’å„ªå…ˆæ¤œç´¢", value=True)
        with col2:
            symptoms = st.multiselect("ç¢ºèªã•ã‚ŒãŸç—‡çŠ¶", SYMPTOMS, default=["åŸå› ä¸æ˜ï¼ˆç·åˆï¼‰"])
            want_plan = st.checkbox("ä¿å…¨è¨ˆç”»ãƒ»LCCè¦³ç‚¹ã‚’å«ã‚ã‚‹", value=(template_name == "å±‹ä¸Šï¼ˆé˜²æ°´ã‚·ãƒ¼ãƒˆï¼‰"))
            
        free_text = st.text_area("è£œè¶³æƒ…å ±ï¼ˆä»»æ„ï¼‰", placeholder="ä¾‹ï¼šé¡•å¾®é¡ç”»åƒã¯ã²ã³å‰²ã‚Œæ·±éƒ¨ã‚’æ’®å½±ã€‚ç¯‰30å¹´ã€‚", height=80)
        
        # è‡ªå‹•ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
        auto_q = build_auto_question(template_name, symptoms, free_text, want_threshold, want_plan)
        
        with st.expander("ğŸ“ è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸRAGæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç¢ºèª", expanded=True):
            st.text_area("æ¤œç´¢ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç·¨é›†å¯ï¼‰", value=auto_q, height=140, label_visibility="collapsed")
            
        st.info("ğŸ’¡ **æ’®å½±ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**: " + " / ".join(TEMPLATES[template_name]["checklist"]) )
        st.markdown('</div>', unsafe_allow_html=True)

    # --- Tab 2: ç”»åƒå…¥åŠ› (é¡•å¾®é¡å¯¾å¿œ) ---
    with tab2:
        col_input, col_gallery = st.columns([1, 2])
        
        with col_input:
            st.markdown('<div class="app-card">', unsafe_allow_html=True)
            st.markdown('<div class="card-header">ğŸ“· ç”»åƒè¿½åŠ </div>', unsafe_allow_html=True)
            
            # Sub-tabs for image types
            tab_vis, tab_ir, tab_micro = st.tabs(["å¯è¦–ç”»åƒ", "IRç”»åƒ", "ğŸ”¬ é¡•å¾®é¡"])
            
            with tab_vis:
                if HAVE_BACK_CAM:
                    bc_img = back_camera_input(key="vis_back")
                    if bc_img:
                        if st.button("ç¾åœ¨ã®æ˜ åƒã‚’è¿½åŠ ", key="btn_add_back"):
                            add_image_to_gallery(Image.open(io.BytesIO(bc_img)), "vis_gallery")
                vis_cam = st.camera_input("ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©æ’®å½±", key="vis_cam", label_visibility="collapsed")
                if vis_cam: add_image_to_gallery(Image.open(vis_cam), "vis_gallery")
                vis_files = st.file_uploader("ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰é¸æŠ", type=["jpg","png"], accept_multiple_files=True, key="vis_up")
                if vis_files:
                    for f in vis_files: add_image_to_gallery(Image.open(f), "vis_gallery")

            with tab_ir:
                st.caption("èµ¤å¤–ç·šã‚µãƒ¼ãƒ¢ã‚°ãƒ©ãƒ•ã‚£ç”»åƒ")
                ir_files = st.file_uploader("IRç”»åƒã‚’é¸æŠ", type=["jpg","png"], accept_multiple_files=True, key="ir_up")
                if ir_files:
                    for f in ir_files: add_image_to_gallery(Image.open(f), "ir_gallery")
                
                with st.expander("IRæ’®å½±æ¡ä»¶ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰"):
                    st.session_state["ir_emiss"] = st.text_input("æ”¾å°„ç‡ Îµ", "0.95")
                    st.session_state["ir_tref"] = st.text_input("åå°„æ¸©åº¦ [â„ƒ]", "20.0")

            with tab_micro:
                st.caption("1000å€é¡•å¾®é¡ãªã©ã®æ‹¡å¤§ç”»åƒ")
                st.info("å¾®ç´°ãªã²ã³å‰²ã‚Œã€æ±šã‚Œã®çµæ™¶ã€å¡—è†œã®è’ã‚Œãªã©ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                micro_files = st.file_uploader("é¡•å¾®é¡ç”»åƒã‚’é¸æŠ", type=["jpg","png"], accept_multiple_files=True, key="micro_up")
                
                # PCç›´çµé¡•å¾®é¡ãŒWebã‚«ãƒ¡ãƒ©èªè­˜ã•ã‚Œã‚‹å ´åˆã®å¯¾å¿œ
                use_micro_cam = st.checkbox("é¡•å¾®é¡ã‚«ãƒ¡ãƒ©å…¥åŠ›ã‚’ä½¿ã†")
                if use_micro_cam:
                    micro_cam = st.camera_input("é¡•å¾®é¡ã‚«ãƒ¡ãƒ©", key="micro_cam")
                    if micro_cam: add_image_to_gallery(Image.open(micro_cam), "micro_gallery")

                if micro_files:
                    for f in micro_files: add_image_to_gallery(Image.open(f), "micro_gallery")

            st.markdown('</div>', unsafe_allow_html=True)

        with col_gallery:
            st.markdown('<div class="app-card">', unsafe_allow_html=True)
            total_imgs = sum(len(st.session_state[k]) for k in ["vis_gallery", "ir_gallery", "micro_gallery"])
            st.markdown(f'<div class="card-header">ğŸ–¼ï¸ ã‚®ãƒ£ãƒ©ãƒªãƒ¼ ({total_imgs}/{MAX_IMAGES_TOTAL})</div>', unsafe_allow_html=True)
            
            if total_imgs == 0:
                st.info("ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚å·¦å´ã‹ã‚‰è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
            
            # Helper to display gallery grid
            def show_grid(key, label):
                if st.session_state[key]:
                    st.caption(f"**{label}**")
                    cols = st.columns(4)
                    for i, img in enumerate(st.session_state[key]):
                        with cols[i % 4]:
                            st.image(img, use_container_width=True)
                            if st.button("å‰Šé™¤", key=f"del_{key}_{i}", use_container_width=True):
                                st.session_state[key].pop(i)
                                st.rerun()

            show_grid("vis_gallery", "å¯è¦–ç”»åƒ")
            show_grid("ir_gallery", "IRç”»åƒ")
            show_grid("micro_gallery", "ğŸ”¬ é¡•å¾®é¡ç”»åƒ")
            
            st.markdown('</div>', unsafe_allow_html=True)

    # --- Tab 3: ä½ç½®æƒ…å ± ---
    with tab3:
        st.markdown('<div class="app-card">', unsafe_allow_html=True)
        st.markdown('<div class="card-header">ğŸ“ è¨ºæ–­å ´æ‰€</div>', unsafe_allow_html=True)
        
        col_map, col_coords = st.columns([2, 1])
        with col_coords:
            st.write("ä½ç½®æƒ…å ±ã‚’æŒ‡å®šï¼ˆä»»æ„ï¼‰")
            lat_in = st.number_input("ç·¯åº¦", value=35.658581, format="%.6f")
            lon_in = st.number_input("çµŒåº¦", value=139.745433, format="%.6f")
        with col_map:
            m = folium.Map(location=[lat_in, lon_in], zoom_start=16)
            folium.Marker([lat_in, lon_in], tooltip="å¯¾è±¡").add_to(m)
            st_folium(m, height=300, use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)

    # --- Tab 4: å®Ÿè¡Œ ---
    with tab4:
        st.markdown('<div class="app-card">', unsafe_allow_html=True)
        st.markdown('<div class="card-header">ğŸš€ è¨ºæ–­å®Ÿè¡Œ</div>', unsafe_allow_html=True)
        
        valid = True
        if not (st.session_state["vis_gallery"] or st.session_state["ir_gallery"] or st.session_state["micro_gallery"]):
            st.error("âš ï¸ ç”»åƒãŒ1æšã‚‚ã‚ã‚Šã¾ã›ã‚“ã€‚è¨ºæ–­ã§ãã¾ã›ã‚“ã€‚")
            valid = False
        if not has_api_key:
            st.error("âš ï¸ Gemini API KeyãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            valid = False
        
        if valid:
            if st.button("AIè¨ºæ–­ã‚’é–‹å§‹ã™ã‚‹ (Gemini 2.5)", type="primary", use_container_width=True):
                with st.spinner("è¨ºæ–­ä¸­... RAGæ¤œç´¢ã¨ç”»åƒè§£æã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™"):
                    # 1. RAG Search (Real Logic)
                    weights = {
                        "base_weight": 1.18, "plan_weight": 1.18, "other_weight": 1.0,
                        "material_boost": 1.15, "defect_boost": 1.15, "mat_def_synergy": 1.1,
                        "number_boost": 1.15, "ir_boost": 1.12, "muni_boost": 1.15
                    }
                    if TEMPLATES[template_name]["rag_preset"] == "base_focus":
                        weights["base_weight"] = 1.25
                    
                    k = 4 if fast_mode else MAX_SNIPPETS
                    # IRãŒã‚ã‚‹ã‹ã€é¡•å¾®é¡ãŒã‚ã‚‹ã‹ï¼Ÿï¼ˆé¡•å¾®é¡ã‚‚IRåŒæ§˜ã«è©³ç´°è§£æãƒ•ãƒ©ã‚°ã¨ã—ã¦æ‰±ã†ã‹æ¤œè¨ï¼‰
                    have_ir_or_micro = bool(st.session_state["ir_gallery"] or st.session_state["micro_gallery"])
                    snippets = rag_search(auto_q, have_ir_or_micro, k, weights)
                    
                    # 2. Image Analysis (Simple stats)
                    vis_list = [analyze_visual(img, 128 if fast_mode else 256) for img in st.session_state["vis_gallery"]]
                    ir_list = [analyze_ir(img, {}, 128 if fast_mode else 256) for img in st.session_state["ir_gallery"]]
                    micro_list = [analyze_visual(img, 256) for img in st.session_state["micro_gallery"]] # é¡•å¾®é¡ã‚‚ä¸€å¿œçµ±è¨ˆã‚’å–ã‚‹

                    grade, reason = rule_based_grade(vis_list, ir_list)
                    life_map = {"A": "10-20å¹´", "B": "7-15å¹´", "C": "3-10å¹´", "D": "1-5å¹´"}
                    
                    # 3. Prompt Construction
                    prompt, labeled_rag = build_master_prompt(
                        user_q=auto_q,
                        rag_snippets=snippets,
                        priors="å†™çœŸã®ã¿ã‹ã‚‰å¯¸æ³•æ–­å®šä¸å¯ã€‚å®‰å…¨å´åˆ¤æ–­ã‚’å„ªå…ˆã€‚",
                        vis_list=vis_list,
                        ir_list=ir_list,
                        micro_list=micro_list, # é¡•å¾®é¡ãƒªã‚¹ãƒˆ
                        rule_grade=grade,
                        rule_life=life_map.get(grade, "ä¸æ˜"),
                        ir_meta_note="æ³¨: IRã¯ç›¸å¯¾æ¸©åº¦ã€‚"
                    )
                    
                    # 4. Gemini Payload Construction
                    img_parts = []
                    
                    # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰æ™‚ã®ç”»åƒé¸æŠœ
                    # å¯è¦–: ä¸Šä½2æš, IR: ä¸Šä½1æš, é¡•å¾®é¡: å…¨ã¦(é‡è¦ãªã®ã§)
                    target_vis = st.session_state["vis_gallery"][:2] if fast_mode else st.session_state["vis_gallery"]
                    target_ir = st.session_state["ir_gallery"][:1] if fast_mode else st.session_state["ir_gallery"]
                    target_micro = st.session_state["micro_gallery"] # é¡•å¾®é¡ã¯æ¸›ã‚‰ã•ãªã„
                    
                    for img in target_vis:
                        img_parts.append(image_to_inline_part(img))
                    for img in target_ir:
                        img_parts.append(image_to_inline_part(img))
                    for img in target_micro:
                        # é¡•å¾®é¡ã¯é«˜è§£åƒåº¦ã§é€ã‚‹
                        img_parts.append(image_to_inline_part(img, max_width=1600))
                    
                    try:
                        res = call_gemini(st.secrets["gemini"]["API_KEY"], prompt, img_parts)
                        report_text = res["candidates"][0]["content"]["parts"][0]["text"]
                        
                        st.success("è¨ºæ–­å®Œäº†ï¼")
                        st.markdown('<div class="app-card">', unsafe_allow_html=True)
                        st.markdown("### ğŸ“ è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ")
                        st.markdown(report_text)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Download Buttons
                        st.download_button(
                            "ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (Markdown)", 
                            report_text.encode("utf-8"), 
                            "report.md", 
                            "text/markdown"
                        )
                        
                        with st.expander("ğŸ“š å‚ç…§ã—ãŸæ–‡çŒ®æ ¹æ‹  (RAG)"):
                            for d in labeled_rag:
                                st.markdown(f"**[{d.get('_rag_id')}] {d.get('doc')}**")
                                st.caption(d.get('text'))
                                st.divider()
                                
                    except Exception as e:
                        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        if debug_mode: st.exception(e)
                        
                        # Fallback
                        st.warning("âš ï¸ ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰ã§ç°¡æ˜“çµæœã‚’è¡¨ç¤ºã—ã¾ã™")
                        st.markdown(f"### æš«å®šè©•ä¾¡: {grade}")
                        st.write(f"ç†ç”±: {reason}")
        
        st.markdown('</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()
